{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Image DR-GAN デモ\n",
    "\n",
    "1. CFP 顔画像データセットの前処理，入力データの作成\n",
    "2. Single Image DR-GANモデルの定義\n",
    "3. 学習の定義\n",
    "4. パラメータ指定，学習の実行\n",
    "5. 学習結果の読み込み， 画像の生成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. CFP 顔画像データセットの前処理，入力データの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from skimage import io, transform\n",
    "from matplotlib import pylab as plt\n",
    "%matplotlib inline\n",
    "from tqdm import tqdm\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CFP の画像を 長辺を指定した長さに， 短辺は 変換後に リサイズするクラス\n",
    "\n",
    "class Resize(object):\n",
    "    #  assume image  as H x W x C numpy array\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, int)\n",
    "        self.output_size = output_size\n",
    "        \n",
    "    def __call__(self, image):\n",
    "        h, w = image.shape[:2]\n",
    "        if h > w:\n",
    "            new_h, new_w = self.output_size, int(self.output_size * w / h)\n",
    "        else:\n",
    "            new_h, new_w = int(self.output_size * h / w), self.output_size\n",
    "\n",
    "        resized_image = transform.resize(image, (new_h, new_w))\n",
    "        \n",
    "        if h>w:\n",
    "            diff = self.output_size - new_w\n",
    "            if diff%2 == 0:\n",
    "                pad_l = int(diff/2)\n",
    "                pad_s = int(diff/2)\n",
    "            else:\n",
    "                pad_l = int(diff/2)+1\n",
    "                pad_s = int(diff/2)\n",
    "\n",
    "            padded_image = np.lib.pad(resized_image, ((0,0), (pad_l,pad_s), (0,0)), 'edge')\n",
    "\n",
    "        else:\n",
    "            diff = self.output_size - new_h\n",
    "            if diff%2==0:\n",
    "                pad_l = int(diff/2)\n",
    "                pad_s = int(diff/2)\n",
    "            else:\n",
    "                pad_l = int(diff/2)+1\n",
    "                pad_s = int(diff/2)\n",
    "\n",
    "            padded_image = np.lib.pad(resized_image, ((pad_l,pad_s), (0,0),  (0,0)), 'edge')\n",
    "\n",
    "        return padded_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:54<00:00,  9.13it/s]\n"
     ]
    }
   ],
   "source": [
    "# 画像をロードし，長辺 110pix 短編 110pix になるようにエッジの画素値で padding\n",
    "\n",
    "image_dir = \"../cfp-dataset/Data/Images/\"\n",
    "rsz = Resize(110)\n",
    "\n",
    "Indv_dir = []\n",
    "for x in os.listdir(image_dir):\n",
    "    if os.path.isdir(os.path.join(image_dir, x)):\n",
    "        Indv_dir.append(x)\n",
    "        \n",
    "Indv_dir=np.sort(Indv_dir)\n",
    "\n",
    "images = np.zeros((7000, 110, 110, 3))\n",
    "id_labels = np.zeros(7000)\n",
    "pose_labels = np.zeros(7000)\n",
    "count = 0\n",
    "gray_count = 0\n",
    "\n",
    "for i in tqdm(range(len(Indv_dir))):\n",
    "    Frontal_dir = os.path.join(image_dir, Indv_dir[i], 'frontal')\n",
    "    Profile_dir = os.path.join(image_dir, Indv_dir[i], 'profile')\n",
    "    \n",
    "    front_img_files = os.listdir(Frontal_dir)\n",
    "    prof_img_files = os.listdir(Profile_dir)\n",
    "    \n",
    "    for img_file in front_img_files:\n",
    "        img = io.imread(os.path.join(Frontal_dir, img_file))\n",
    "        if len(img.shape)==2:\n",
    "            gray_count = gray_count+1\n",
    "            continue\n",
    "        img_rsz = rsz(img)\n",
    "        images[count] = img_rsz\n",
    "        id_labels[count] = i\n",
    "        pose_labels[count] = 0\n",
    "        count = count + 1\n",
    "    \n",
    "    for img_file in prof_img_files:\n",
    "        img = io.imread(os.path.join(Profile_dir, img_file))\n",
    "        if len(img.shape)==2:\n",
    "            gray_count = gray_count+1\n",
    "            continue\n",
    "        img_rsz = rsz(img)\n",
    "        images[count] = img_rsz\n",
    "        id_labels[count] = i\n",
    "        pose_labels[count] = 1\n",
    "        count = count + 1\n",
    "    \n",
    "id_labels = id_labels.astype('int64')\n",
    "pose_labels = pose_labels.astype('int64')\n",
    "\n",
    "#[0,255] -> [-1,1]\n",
    "images = images *2 - 1\n",
    "# RGB -> BGR\n",
    "images = images[:,:,:,[2,1,0]]\n",
    "# B x H x W x C-> B x C x H x W\n",
    "images = images.transpose(0, 3, 1, 2)\n",
    "\n",
    "# 白黒画像データを取り除く\n",
    "images = images[:gray_count*-1]\n",
    "id_labels = id_labels[:gray_count*-1]\n",
    "pose_labels = pose_labels[:gray_count*-1]\n",
    "Np = int(pose_labels.max() + 1)\n",
    "Nd = int(id_labels.max() + 1)\n",
    "Nz = 50\n",
    "channel_num = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Single-Image DRGANモデルの定義 (model/single_DR_GAN_model.py)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# encoding: utf-8\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "import pdb\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    \"\"\"\n",
    "    multi-task CNN for identity and pose classification\n",
    "\n",
    "    ### init\n",
    "    Nd : Number of identitiy to classify\n",
    "    Np : Number of pose to classify\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, Nd, Np, channel_num):\n",
    "        super(Discriminator, self).__init__()\n",
    "        convLayers = [\n",
    "            nn.Conv2d(channel_num, 32, 3, 1, 1, bias=False), # Bxchx96x96 -> Bx32x96x96\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ELU(),\n",
    "            nn.Conv2d(32, 64, 3, 1, 1, bias=False), # Bx32x96x96 -> Bx64x96x96\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ELU(),\n",
    "            nn.ZeroPad2d((0, 1, 0, 1)),                      # Bx64x96x96 -> Bx64x97x97\n",
    "            nn.Conv2d(64, 64, 3, 2, 0, bias=False), # Bx64x97x97 -> Bx64x48x48\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ELU(),\n",
    "            nn.Conv2d(64, 64, 3, 1, 1, bias=False), # Bx64x48x48 -> Bx64x48x48\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ELU(),\n",
    "            nn.Conv2d(64, 128, 3, 1, 1, bias=False), # Bx64x48x48 -> Bx128x48x48\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ELU(),\n",
    "            nn.ZeroPad2d((0, 1, 0, 1)),                      # Bx128x48x48 -> Bx128x49x49\n",
    "            nn.Conv2d(128, 128, 3, 2, 0, bias=False), #  Bx128x49x49 -> Bx128x24x24\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ELU(),\n",
    "            nn.Conv2d(128, 96, 3, 1, 1, bias=False), #  Bx128x24x24 -> Bx96x24x24\n",
    "            nn.BatchNorm2d(96),\n",
    "            nn.ELU(),\n",
    "            nn.Conv2d(96, 192, 3, 1, 1, bias=False), #  Bx96x24x24 -> Bx192x24x24\n",
    "            nn.BatchNorm2d(192),\n",
    "            nn.ELU(),\n",
    "            nn.ZeroPad2d((0, 1, 0, 1)),                      # Bx192x24x24 -> Bx192x25x25\n",
    "            nn.Conv2d(192, 192, 3, 2, 0, bias=False), # Bx192x25x25 -> Bx192x12x12\n",
    "            nn.BatchNorm2d(192),\n",
    "            nn.ELU(),\n",
    "            nn.Conv2d(192, 128, 3, 1, 1, bias=False), # Bx192x12x12 -> Bx128x12x12\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ELU(),\n",
    "            nn.Conv2d(128, 256, 3, 1, 1, bias=False), # Bx128x12x12 -> Bx256x12x12\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ELU(),\n",
    "            nn.ZeroPad2d((0, 1, 0, 1)),                      # Bx256x12x12 -> Bx256x13x13\n",
    "            nn.Conv2d(256, 256, 3, 2, 0, bias=False),  # Bx256x13x13 -> Bx256x6x6\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ELU(),\n",
    "            nn.Conv2d(256, 160, 3, 1, 1, bias=False), # Bx256x6x6 -> Bx160x6x6\n",
    "            nn.BatchNorm2d(160),\n",
    "            nn.ELU(),\n",
    "            nn.Conv2d(160, 320, 3, 1, 1, bias=False), # Bx160x6x6 -> Bx320x6x6\n",
    "            nn.BatchNorm2d(320),\n",
    "            nn.ELU(),\n",
    "            nn.AvgPool2d(6, stride=1), #  Bx320x6x6 -> Bx320x1x1\n",
    "        ]\n",
    "\n",
    "        self.convLayers = nn.Sequential(*convLayers)\n",
    "        self.fc = nn.Linear(320, Nd+1+Np)\n",
    "\n",
    "        # 重みは全て N(0, 0.02) で初期化\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                m.weight.data.normal_(0, 0.02)\n",
    "\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                m.weight.data.normal_(0, 0.02)\n",
    "\n",
    "    def forward(self, input):\n",
    "        # 畳み込み -> 平均プーリングの結果 B x 320 x 1 x 1の出力を得る\n",
    "        x = self.convLayers(input)\n",
    "\n",
    "        # バッチ数次元を消さないように１次元の次元を削除　\n",
    "        x = x.squeeze(2)\n",
    "        x = x.squeeze(2)\n",
    "\n",
    "        # 全結合\n",
    "        x = self.fc(x) # Bx320 -> B x (Nd+1+Np)\n",
    "\n",
    "        return x\n",
    "\n",
    "class Crop(nn.Module):\n",
    "    \"\"\"\n",
    "    Generator でのアップサンプリング時に， ダウンサンプル時のZeroPad2d と逆の事をするための関数\n",
    "    論文著者が Tensorflow で padding='SAME' オプションで自動的にパディングしているのを\n",
    "    ダウンサンプル時にはZeroPad2dで，アップサンプリング時には Crop で実現\n",
    "\n",
    "    ### init\n",
    "    crop_list : データの上下左右をそれぞれどれくらい削るか指定\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, crop_list):\n",
    "        super(Crop, self).__init__()\n",
    "\n",
    "        # crop_lsit = [crop_top, crop_bottom, crop_left, crop_right]\n",
    "        self.crop_list = crop_list\n",
    "\n",
    "    def forward(self, x):\n",
    "        B,C,H,W = x.size()\n",
    "        x = x[:,:, self.crop_list[0] : H - self.crop_list[1] , self.crop_list[2] : W - self.crop_list[3]]\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    \"\"\"\n",
    "    Encoder/Decoder conditional GAN conditioned with pose vector and noise vector\n",
    "\n",
    "    ### init\n",
    "    Np : Dimension of pose vector (Corresponds to number of dicrete pose classes of the data)\n",
    "    Nz : Dimension of noise vector\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, Np, Nz, channel_num):\n",
    "        super(Generator, self).__init__()\n",
    "        self.features = []\n",
    "\n",
    "        G_enc_convLayers = [\n",
    "            nn.Conv2d(channel_num, 32, 3, 1, 1, bias=False), # Bx3x96x96 -> Bx32x96x96\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ELU(),\n",
    "            nn.Conv2d(32, 64, 3, 1, 1, bias=False), # Bx32x96x96 -> Bx64x96x96\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ELU(),\n",
    "            nn.ZeroPad2d((0, 1, 0, 1)),                      # Bx64x96x96 -> Bx64x97x97\n",
    "            nn.Conv2d(64, 64, 3, 2, 0, bias=False), # Bx64x97x97 -> Bx64x48x48\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ELU(),\n",
    "            nn.Conv2d(64, 64, 3, 1, 1, bias=False), # Bx64x48x48 -> Bx64x48x48\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ELU(),\n",
    "            nn.Conv2d(64, 128, 3, 1, 1, bias=False), # Bx64x48x48 -> Bx128x48x48\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ELU(),\n",
    "            nn.ZeroPad2d((0, 1, 0, 1)),                      # Bx128x48x48 -> Bx128x49x49\n",
    "            nn.Conv2d(128, 128, 3, 2, 0, bias=False), #  Bx128x49x49 -> Bx128x24x24\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ELU(),\n",
    "            nn.Conv2d(128, 96, 3, 1, 1, bias=False), #  Bx128x24x24 -> Bx96x24x24\n",
    "            nn.BatchNorm2d(96),\n",
    "            nn.ELU(),\n",
    "            nn.Conv2d(96, 192, 3, 1, 1, bias=False), #  Bx96x24x24 -> Bx192x24x24\n",
    "            nn.BatchNorm2d(192),\n",
    "            nn.ELU(),\n",
    "            nn.ZeroPad2d((0, 1, 0, 1)),                      # Bx192x24x24 -> Bx192x25x25\n",
    "            nn.Conv2d(192, 192, 3, 2, 0, bias=False), # Bx192x25x25 -> Bx192x12x12\n",
    "            nn.BatchNorm2d(192),\n",
    "            nn.ELU(),\n",
    "            nn.Conv2d(192, 128, 3, 1, 1, bias=False), # Bx192x12x12 -> Bx128x12x12\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ELU(),\n",
    "            nn.Conv2d(128, 256, 3, 1, 1, bias=False), # Bx128x12x12 -> Bx256x12x12\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ELU(),\n",
    "            nn.ZeroPad2d((0, 1, 0, 1)),                      # Bx256x12x12 -> Bx256x13x13\n",
    "            nn.Conv2d(256, 256, 3, 2, 0, bias=False),  # Bx256x13x13 -> Bx256x6x6\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ELU(),\n",
    "            nn.Conv2d(256, 160, 3, 1, 1, bias=False), # Bx256x6x6 -> Bx160x6x6\n",
    "            nn.BatchNorm2d(160),\n",
    "            nn.ELU(),\n",
    "            nn.Conv2d(160, 320, 3, 1, 1, bias=False), # Bx160x6x6 -> Bx320x6x6\n",
    "            nn.BatchNorm2d(320),\n",
    "            nn.ELU(),\n",
    "            nn.AvgPool2d(6, stride=1), #  Bx320x6x6 -> Bx320x1x1\n",
    "\n",
    "        ]\n",
    "        self.G_enc_convLayers = nn.Sequential(*G_enc_convLayers)\n",
    "\n",
    "        G_dec_convLayers = [\n",
    "            nn.ConvTranspose2d(320,160, 3,1,1, bias=False), # Bx320x6x6 -> Bx160x6x6\n",
    "            nn.BatchNorm2d(160),\n",
    "            nn.ELU(),\n",
    "            nn.ConvTranspose2d(160, 256, 3,1,1, bias=False), # Bx160x6x6 -> Bx256x6x6\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ELU(),\n",
    "            nn.ConvTranspose2d(256, 256, 3,2,0, bias=False), # Bx256x6x6 -> Bx256x13x13\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ELU(),\n",
    "            Crop([0, 1, 0, 1]),\n",
    "            nn.ConvTranspose2d(256, 128, 3,1,1, bias=False), # Bx256x12x12 -> Bx128x12x12\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ELU(),\n",
    "            nn.ConvTranspose2d(128, 192,  3,1,1, bias=False), # Bx128x12x12 -> Bx192x12x12\n",
    "            nn.BatchNorm2d(192),\n",
    "            nn.ELU(),\n",
    "            nn.ConvTranspose2d(192, 192,  3,2,0, bias=False), # Bx128x12x12 -> Bx192x25x25\n",
    "            nn.BatchNorm2d(192),\n",
    "            nn.ELU(),\n",
    "            Crop([0, 1, 0, 1]),\n",
    "            nn.ConvTranspose2d(192, 96,  3,1,1, bias=False), # Bx192x24x24 -> Bx96x24x24\n",
    "            nn.BatchNorm2d(96),\n",
    "            nn.ELU(),\n",
    "            nn.ConvTranspose2d(96, 128,  3,1,1, bias=False), # Bx96x24x24 -> Bx128x24x24\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ELU(),\n",
    "            nn.ConvTranspose2d(128, 128,  3,2,0, bias=False), # Bx128x24x24 -> Bx128x49x49\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ELU(),\n",
    "            Crop([0, 1, 0, 1]),\n",
    "            nn.ConvTranspose2d(128, 64,  3,1,1, bias=False), # Bx128x48x48 -> Bx64x48x48\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ELU(),\n",
    "            nn.ConvTranspose2d(64, 64,  3,1,1, bias=False), # Bx64x48x48 -> Bx64x48x48\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ELU(),\n",
    "            nn.ConvTranspose2d(64, 64,  3,2,0, bias=False), # Bx64x48x48 -> Bx64x97x97\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ELU(),\n",
    "            Crop([0, 1, 0, 1]),\n",
    "            nn.ConvTranspose2d(64, 32,  3,1,1, bias=False), # Bx64x96x96 -> Bx32x96x96\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ELU(),\n",
    "            nn.ConvTranspose2d(32, channel_num,  3,1,1, bias=False), # Bx32x96x96 -> Bxchx96x96\n",
    "            nn.Tanh(),\n",
    "        ]\n",
    "\n",
    "        self.G_dec_convLayers = nn.Sequential(*G_dec_convLayers)\n",
    "\n",
    "        self.G_dec_fc = nn.Linear(320+Np+Nz, 320*6*6)\n",
    "\n",
    "        # 重みは全て N(0, 0.02) で初期化\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                m.weight.data.normal_(0, 0.02)\n",
    "\n",
    "            elif isinstance(m, nn.ConvTranspose2d):\n",
    "                m.weight.data.normal_(0, 0.02)\n",
    "\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                m.weight.data.normal_(0, 0.02)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, input, pose, noise):\n",
    "        \n",
    "        x = self.G_enc_convLayers(input) # Bxchx96x96 -> Bx320x1x1\n",
    "\n",
    "        x = x.squeeze(2)\n",
    "        x = x.squeeze(2)\n",
    "\n",
    "        self.features = x\n",
    "\n",
    "        x = torch.cat([x, pose, noise], 1)  # Bx320 -> B x (320+Np+Nz)\n",
    "\n",
    "        x = self.G_dec_fc(x) # B x (320+Np+Nz) -> B x (320x6x6)\n",
    "\n",
    "        x = x.view(-1, 320, 6, 6) # B x (320x6x6) -> B x 320 x 6 x 6\n",
    "\n",
    "        x = self.G_dec_convLayers(x) #  B x 320 x 6 x 6 -> Bxchx96x96\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 学習の定義 (train_single_DRGAN.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# encoding: utf-8\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy import misc\n",
    "import pdb\n",
    "import matplotlib as mpl\n",
    "mpl.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from util.one_hot import one_hot\n",
    "from util.Is_D_strong import Is_D_strong\n",
    "from util.log_learning import log_learning\n",
    "from util.convert_image import convert_image\n",
    "from util.DataAugmentation import FaceIdPoseDataset, Resize, RandomCrop\n",
    "\n",
    "\n",
    "\n",
    "def train_single_DRGAN(images, id_labels, pose_labels, Nd, Np, Nz, D_model, G_model, args):\n",
    "    if args.cuda:\n",
    "        D_model.cuda()\n",
    "        G_model.cuda()\n",
    "\n",
    "    D_model.train()\n",
    "    G_model.train()\n",
    "\n",
    "    lr_Adam    = args.lr\n",
    "    beta1_Adam = args.beta1\n",
    "    beta2_Adam = args.beta2\n",
    "\n",
    "    image_size = images.shape[0]\n",
    "    epoch_time = np.ceil(image_size / args.batch_size).astype(int)\n",
    "\n",
    "    optimizer_D = optim.Adam(D_model.parameters(), lr = lr_Adam, betas=(beta1_Adam, beta2_Adam))\n",
    "    optimizer_G = optim.Adam(G_model.parameters(), lr = lr_Adam, betas=(beta1_Adam, beta2_Adam))\n",
    "    loss_criterion = nn.CrossEntropyLoss()\n",
    "    loss_criterion_gan = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    loss_log = []\n",
    "    steps = 0\n",
    "\n",
    "    flag_D_strong  = False\n",
    "    for epoch in range(1,args.epochs+1):\n",
    "\n",
    "        # Load augmented data\n",
    "        transformed_dataset = FaceIdPoseDataset(images, id_labels, pose_labels,\n",
    "                                        transform = transforms.Compose([Resize((110,110)), RandomCrop((96,96))]))\n",
    "        dataloader = DataLoader(transformed_dataset, batch_size = args.batch_size, shuffle=True)\n",
    "\n",
    "        for i, batch_data in enumerate(dataloader):\n",
    "            D_model.zero_grad()\n",
    "            G_model.zero_grad()\n",
    "\n",
    "            batch_image = torch.FloatTensor(batch_data[0].float())\n",
    "            batch_id_label = batch_data[1]\n",
    "            batch_pose_label = batch_data[2]\n",
    "            minibatch_size = len(batch_image)\n",
    "\n",
    "            batch_ones_label = torch.ones(minibatch_size)   # 真偽判別用のラベル\n",
    "            batch_zeros_label = torch.zeros(minibatch_size)\n",
    "\n",
    "\n",
    "            # ノイズと姿勢コードを生成\n",
    "            fixed_noise = torch.FloatTensor(np.random.uniform(-1,1, (minibatch_size, Nz)))\n",
    "            tmp  = torch.LongTensor(np.random.randint(Np, size=minibatch_size))\n",
    "            pose_code = one_hot(tmp, Np) # Condition 付に使用\n",
    "            pose_code_label = torch.LongTensor(tmp) # CrossEntropy 誤差に使用\n",
    "\n",
    "\n",
    "            if args.cuda:\n",
    "                batch_image, batch_id_label, batch_pose_label, batch_ones_label, batch_zeros_label = \\\n",
    "                    batch_image.cuda(), batch_id_label.cuda(), batch_pose_label.cuda(), batch_ones_label.cuda(), batch_zeros_label.cuda()\n",
    "\n",
    "                fixed_noise, pose_code, pose_code_label = \\\n",
    "                    fixed_noise.cuda(), pose_code.cuda(), pose_code_label.cuda()\n",
    "\n",
    "            batch_image, batch_id_label, batch_pose_label, batch_ones_label, batch_zeros_label = \\\n",
    "                Variable(batch_image), Variable(batch_id_label), Variable(batch_pose_label), Variable(batch_ones_label), Variable(batch_zeros_label)\n",
    "\n",
    "            fixed_noise, pose_code, pose_code_label = \\\n",
    "                Variable(fixed_noise), Variable(pose_code), Variable(pose_code_label)\n",
    "\n",
    "            # Generatorでイメージ生成\n",
    "            generated = G_model(batch_image, pose_code, fixed_noise)\n",
    "\n",
    "            steps += 1\n",
    "\n",
    "            # バッチ毎に交互に D と G の学習，　Dが90%以上の精度の場合は 1:4の比率で学習\n",
    "            if flag_D_strong:\n",
    "\n",
    "                if i%5 == 0:\n",
    "                    # Discriminator の学習\n",
    "                    flag_D_strong = Learn_D(D_model, loss_criterion, loss_criterion_gan, optimizer_D, batch_image, generated, \\\n",
    "                                            batch_id_label, batch_pose_label, batch_ones_label, batch_zeros_label, epoch, steps, Nd, args)\n",
    "\n",
    "                else:\n",
    "                    # Generatorの学習\n",
    "                    Learn_G(D_model, loss_criterion, loss_criterion_gan, optimizer_G ,generated,\\\n",
    "                            batch_id_label, batch_ones_label, pose_code_label, epoch, steps, Nd, args)\n",
    "            else:\n",
    "\n",
    "                if i%2==0:\n",
    "                    # Discriminator の学習\n",
    "                    flag_D_strong = Learn_D(D_model, loss_criterion, loss_criterion_gan, optimizer_D, batch_image, generated, \\\n",
    "                                            batch_id_label, batch_pose_label, batch_ones_label, batch_zeros_label, epoch, steps, Nd, args)\n",
    "\n",
    "                else:\n",
    "                    # Generatorの学習\n",
    "                    Learn_G(D_model, loss_criterion, loss_criterion_gan, optimizer_G ,generated, \\\n",
    "                            batch_id_label, batch_ones_label, pose_code_label, epoch, steps, Nd, args)\n",
    "\n",
    "\n",
    "        if epoch%args.save_freq == 0:\n",
    "            # 各エポックで学習したモデルを保存\n",
    "            if not os.path.isdir(args.save_dir): os.makedirs(args.save_dir)\n",
    "            save_path_D = os.path.join(args.save_dir,'epoch{}_D.pt'.format(epoch))\n",
    "            torch.save(D_model, save_path_D)\n",
    "            save_path_G = os.path.join(args.save_dir,'epoch{}_G.pt'.format(epoch))\n",
    "            torch.save(G_model, save_path_G)\n",
    "            # 最後のエポックの学習前に生成した画像を１枚保存（学習の確認用）\n",
    "            save_generated_image = convert_image(generated[0].cpu().data.numpy())\n",
    "            save_path_image = os.path.join(args.save_dir, 'epoch{}_generatedimage.jpg'.format(epoch))\n",
    "            misc.imsave(save_path_image, save_generated_image.astype(np.uint8))\n",
    "\n",
    "\n",
    "\n",
    "def Learn_D(D_model, loss_criterion, loss_criterion_gan, optimizer_D, batch_image, generated, \\\n",
    "            batch_id_label, batch_pose_label, batch_ones_label, batch_zeros_label, epoch, steps, Nd, args):\n",
    "\n",
    "    real_output = D_model(batch_image)\n",
    "    syn_output = D_model(generated.detach()) # .detach() をすることで Generatorまでの逆伝播計算省略\n",
    "\n",
    "    # id,真偽, pose それぞれのロスを計算\n",
    "    L_id    = loss_criterion(real_output[:, :Nd], batch_id_label)\n",
    "    L_gan   = loss_criterion_gan(real_output[:, Nd], batch_ones_label) + loss_criterion_gan(syn_output[:, Nd], batch_zeros_label)\n",
    "    L_pose  = loss_criterion(real_output[:, Nd+1:], batch_pose_label)\n",
    "\n",
    "    d_loss = L_gan + L_id + L_pose\n",
    "\n",
    "    d_loss.backward()\n",
    "    optimizer_D.step()\n",
    "    log_learning(epoch, steps, 'D', d_loss.data[0], args)\n",
    "\n",
    "    # Discriminator の強さを判別\n",
    "    flag_D_strong = Is_D_strong(real_output, syn_output, batch_id_label, batch_pose_label, Nd)\n",
    "\n",
    "    return flag_D_strong\n",
    "\n",
    "\n",
    "\n",
    "def Learn_G(D_model, loss_criterion, loss_criterion_gan, optimizer_G ,generated, \\\n",
    "            batch_id_label, batch_ones_label, pose_code_label, epoch, steps, Nd, args):\n",
    "\n",
    "    syn_output=D_model(generated)\n",
    "\n",
    "    # id についての出力と元画像のラベル, 真偽, poseについての出力と生成時に与えたposeコード の ロスを計算\n",
    "    L_id    = loss_criterion(syn_output[:, :Nd], batch_id_label)\n",
    "    L_gan   = loss_criterion_gan(syn_output[:, Nd], batch_ones_label)\n",
    "    L_pose  = loss_criterion(syn_output[:, Nd+1:], pose_code_label)\n",
    "\n",
    "    g_loss = L_gan + L_id + L_pose\n",
    "\n",
    "    g_loss.backward()\n",
    "    optimizer_G.step()\n",
    "    log_learning(epoch, steps, 'G', g_loss.data[0], args)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 4. パラメータ指定，学習の実行 (main.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters:\n",
      "\tBATCH_SIZE=64\n",
      "\n",
      "\tBETA1=0.5\n",
      "\n",
      "\tBETA2=0.999\n",
      "\n",
      "\tCUDA=False\n",
      "\n",
      "\tEPOCHS=1000\n",
      "\n",
      "\tLR=0.0002\n",
      "\n",
      "\tSAVE_DIR=snapshot/Single/2019-11-15_03-44-06\n",
      "\n",
      "\tSAVE_FREQ=1\n",
      "\n",
      "EPOCH : 1, step : 1, D : 8.307655334472656\n",
      "EPOCH : 1, step : 2, G : 7.594618797302246\n",
      "EPOCH : 1, step : 3, D : 8.253284454345703\n",
      "EPOCH : 1, step : 4, G : 7.582085609436035\n",
      "EPOCH : 1, step : 5, D : 8.263090133666992\n",
      "EPOCH : 1, step : 6, G : 7.533958435058594\n",
      "EPOCH : 1, step : 7, D : 8.260887145996094\n",
      "EPOCH : 1, step : 8, G : 7.553605556488037\n",
      "EPOCH : 1, step : 9, D : 8.144478797912598\n",
      "EPOCH : 1, step : 10, G : 7.513525009155273\n",
      "EPOCH : 1, step : 11, D : 8.19669246673584\n",
      "EPOCH : 1, step : 12, G : 7.496384620666504\n",
      "EPOCH : 1, step : 13, D : 8.145478248596191\n",
      "EPOCH : 1, step : 14, G : 7.540350437164307\n",
      "EPOCH : 1, step : 15, D : 8.320524215698242\n",
      "EPOCH : 1, step : 16, G : 7.629148960113525\n",
      "EPOCH : 1, step : 17, D : 8.062918663024902\n",
      "EPOCH : 1, step : 18, G : 7.447247505187988\n",
      "EPOCH : 1, step : 19, D : 8.099799156188965\n",
      "EPOCH : 1, step : 20, G : 7.357403755187988\n",
      "EPOCH : 1, step : 21, D : 8.305814743041992\n",
      "EPOCH : 1, step : 22, G : 7.3810811042785645\n",
      "EPOCH : 1, step : 23, D : 8.129384994506836\n",
      "EPOCH : 1, step : 24, G : 7.393552303314209\n",
      "EPOCH : 1, step : 25, D : 8.13113784790039\n",
      "EPOCH : 1, step : 26, G : 7.272427558898926\n",
      "EPOCH : 1, step : 27, D : 8.075319290161133\n",
      "EPOCH : 1, step : 28, G : 7.153862953186035\n",
      "EPOCH : 1, step : 29, D : 8.042227745056152\n",
      "EPOCH : 1, step : 30, G : 7.216799736022949\n",
      "EPOCH : 1, step : 31, D : 8.443479537963867\n",
      "EPOCH : 1, step : 32, G : 7.352128982543945\n",
      "EPOCH : 1, step : 33, D : 8.065274238586426\n",
      "EPOCH : 1, step : 34, G : 7.295553684234619\n",
      "EPOCH : 1, step : 35, D : 8.16777229309082\n",
      "EPOCH : 1, step : 36, G : 7.411851406097412\n",
      "EPOCH : 1, step : 37, D : 8.028626441955566\n",
      "EPOCH : 1, step : 38, G : 7.252007007598877\n",
      "EPOCH : 1, step : 39, D : 8.074684143066406\n",
      "EPOCH : 1, step : 40, G : 7.197548866271973\n",
      "EPOCH : 1, step : 41, D : 8.143511772155762\n",
      "EPOCH : 1, step : 42, G : 7.156480312347412\n",
      "EPOCH : 1, step : 43, D : 8.052567481994629\n",
      "EPOCH : 1, step : 44, G : 7.177088737487793\n",
      "EPOCH : 1, step : 45, D : 8.14254093170166\n",
      "EPOCH : 1, step : 46, G : 7.199832916259766\n",
      "EPOCH : 1, step : 47, D : 8.014939308166504\n",
      "EPOCH : 1, step : 48, G : 7.448027610778809\n",
      "EPOCH : 1, step : 49, D : 7.860646724700928\n",
      "EPOCH : 1, step : 50, G : 7.398536682128906\n",
      "EPOCH : 1, step : 51, D : 7.875180244445801\n",
      "EPOCH : 1, step : 52, G : 7.902192115783691\n",
      "EPOCH : 1, step : 53, D : 7.8091349601745605\n",
      "EPOCH : 1, step : 54, G : 7.598326683044434\n",
      "EPOCH : 1, step : 55, D : 8.184816360473633\n",
      "EPOCH : 1, step : 56, G : 7.2039384841918945\n",
      "EPOCH : 1, step : 57, D : 7.99532413482666\n",
      "EPOCH : 1, step : 58, G : 7.347210884094238\n",
      "EPOCH : 1, step : 59, D : 8.039535522460938\n",
      "EPOCH : 1, step : 60, G : 7.31095027923584\n",
      "EPOCH : 1, step : 61, D : 7.832549095153809\n",
      "EPOCH : 1, step : 62, G : 7.180377960205078\n",
      "EPOCH : 1, step : 63, D : 7.823132038116455\n",
      "EPOCH : 1, step : 64, G : 7.204732418060303\n",
      "EPOCH : 1, step : 65, D : 7.862110137939453\n",
      "EPOCH : 1, step : 66, G : 7.395445823669434\n",
      "EPOCH : 1, step : 67, D : 7.964454174041748\n",
      "EPOCH : 1, step : 68, G : 7.292553424835205\n",
      "EPOCH : 1, step : 69, D : 7.854147911071777\n",
      "EPOCH : 1, step : 70, G : 7.234470844268799\n",
      "EPOCH : 1, step : 71, D : 7.801368236541748\n",
      "EPOCH : 1, step : 72, G : 7.1285719871521\n",
      "EPOCH : 1, step : 73, D : 7.848961353302002\n",
      "EPOCH : 1, step : 74, G : 7.1853532791137695\n",
      "EPOCH : 1, step : 75, D : 7.7994794845581055\n",
      "EPOCH : 1, step : 76, G : 7.262351036071777\n",
      "EPOCH : 1, step : 77, D : 7.876549243927002\n",
      "EPOCH : 1, step : 78, G : 7.161342144012451\n",
      "EPOCH : 1, step : 79, D : 7.863554000854492\n",
      "EPOCH : 1, step : 80, G : 7.19804573059082\n",
      "EPOCH : 1, step : 81, D : 7.720236778259277\n",
      "EPOCH : 1, step : 82, G : 7.080485820770264\n",
      "EPOCH : 1, step : 83, D : 7.84871244430542\n",
      "EPOCH : 1, step : 84, G : 7.08884859085083\n",
      "EPOCH : 1, step : 85, D : 7.712071418762207\n",
      "EPOCH : 1, step : 86, G : 7.032008647918701\n",
      "EPOCH : 1, step : 87, D : 7.759344100952148\n",
      "EPOCH : 1, step : 88, G : 7.0338826179504395\n",
      "EPOCH : 1, step : 89, D : 7.767402648925781\n",
      "EPOCH : 1, step : 90, G : 7.096571922302246\n",
      "EPOCH : 1, step : 91, D : 7.74019718170166\n",
      "EPOCH : 1, step : 92, G : 7.065805912017822\n",
      "EPOCH : 1, step : 93, D : 7.647252559661865\n",
      "EPOCH : 1, step : 94, G : 7.0324859619140625\n",
      "EPOCH : 1, step : 95, D : 7.755804061889648\n",
      "EPOCH : 1, step : 96, G : 7.006982326507568\n",
      "EPOCH : 1, step : 97, D : 7.687049388885498\n",
      "EPOCH : 1, step : 98, G : 7.0446457862854\n",
      "EPOCH : 1, step : 99, D : 7.660990238189697\n",
      "EPOCH : 1, step : 100, G : 7.069769859313965\n",
      "EPOCH : 1, step : 101, D : 7.637392997741699\n",
      "EPOCH : 1, step : 102, G : 7.049245357513428\n",
      "EPOCH : 1, step : 103, D : 7.674957275390625\n",
      "EPOCH : 1, step : 104, G : 7.031660079956055\n",
      "EPOCH : 1, step : 105, D : 7.6379876136779785\n",
      "EPOCH : 1, step : 106, G : 6.908138275146484\n",
      "EPOCH : 1, step : 107, D : 7.588618755340576\n",
      "EPOCH : 1, step : 108, G : 7.041013240814209\n",
      "EPOCH : 1, step : 109, D : 7.614593982696533\n",
      "EPOCH : 1, step : 110, G : 7.001367568969727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anpei/.local/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Discriminator. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/anpei/.local/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Sequential. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/anpei/.local/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Conv2d. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/anpei/.local/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BatchNorm2d. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/anpei/.local/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type ELU. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/anpei/.local/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type ZeroPad2d. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/anpei/.local/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type AvgPool2d. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/anpei/.local/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/anpei/.local/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Generator. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/anpei/.local/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type ConvTranspose2d. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/anpei/.local/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Crop. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/anpei/.local/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Tanh. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 2, step : 111, D : 7.59882926940918\n",
      "EPOCH : 2, step : 112, G : 7.023697853088379\n",
      "EPOCH : 2, step : 113, D : 7.624639511108398\n",
      "EPOCH : 2, step : 114, G : 6.989665985107422\n",
      "EPOCH : 2, step : 115, D : 7.670737266540527\n",
      "EPOCH : 2, step : 116, G : 7.01533842086792\n",
      "EPOCH : 2, step : 117, D : 7.754487991333008\n",
      "EPOCH : 2, step : 118, G : 6.966924667358398\n",
      "EPOCH : 2, step : 119, D : 7.677892208099365\n",
      "EPOCH : 2, step : 120, G : 7.015960216522217\n",
      "EPOCH : 2, step : 121, D : 7.6473164558410645\n",
      "EPOCH : 2, step : 122, G : 6.941712856292725\n",
      "EPOCH : 2, step : 123, D : 7.7122483253479\n",
      "EPOCH : 2, step : 124, G : 7.088972091674805\n",
      "EPOCH : 2, step : 125, D : 7.565810203552246\n",
      "EPOCH : 2, step : 126, G : 6.940740585327148\n",
      "EPOCH : 2, step : 127, D : 7.620291709899902\n",
      "EPOCH : 2, step : 128, G : 6.900816440582275\n",
      "EPOCH : 2, step : 129, D : 7.576470851898193\n",
      "EPOCH : 2, step : 130, G : 6.973528861999512\n",
      "EPOCH : 2, step : 131, D : 7.575857639312744\n",
      "EPOCH : 2, step : 132, G : 6.942293167114258\n",
      "EPOCH : 2, step : 133, D : 7.542068004608154\n",
      "EPOCH : 2, step : 134, G : 7.054178714752197\n",
      "EPOCH : 2, step : 135, D : 7.584583282470703\n",
      "EPOCH : 2, step : 136, G : 6.981250286102295\n",
      "EPOCH : 2, step : 137, D : 7.500577449798584\n",
      "EPOCH : 2, step : 138, G : 7.026050567626953\n",
      "EPOCH : 2, step : 139, D : 7.504095554351807\n",
      "EPOCH : 2, step : 140, G : 7.027822017669678\n",
      "EPOCH : 2, step : 141, D : 7.524071216583252\n",
      "EPOCH : 2, step : 142, G : 6.984498500823975\n",
      "EPOCH : 2, step : 143, D : 7.502110958099365\n",
      "EPOCH : 2, step : 144, G : 6.983563423156738\n",
      "EPOCH : 2, step : 145, D : 7.736562728881836\n",
      "EPOCH : 2, step : 146, G : 7.026157379150391\n",
      "EPOCH : 2, step : 147, D : 7.689751625061035\n",
      "EPOCH : 2, step : 148, G : 7.075392246246338\n",
      "EPOCH : 2, step : 149, D : 7.544513702392578\n",
      "EPOCH : 2, step : 150, G : 7.046445846557617\n",
      "EPOCH : 2, step : 151, D : 7.5181121826171875\n",
      "EPOCH : 2, step : 152, G : 7.001424312591553\n",
      "EPOCH : 2, step : 153, D : 7.587490081787109\n",
      "EPOCH : 2, step : 154, G : 7.069666385650635\n",
      "EPOCH : 2, step : 155, D : 7.5603108406066895\n",
      "EPOCH : 2, step : 156, G : 7.339745044708252\n",
      "EPOCH : 2, step : 157, D : 7.488977432250977\n",
      "EPOCH : 2, step : 158, G : 7.148297309875488\n",
      "EPOCH : 2, step : 159, D : 7.480921268463135\n",
      "EPOCH : 2, step : 160, G : 7.239490032196045\n",
      "EPOCH : 2, step : 161, D : 7.66349458694458\n",
      "EPOCH : 2, step : 162, G : 7.348334312438965\n",
      "EPOCH : 2, step : 163, D : 7.636616230010986\n",
      "EPOCH : 2, step : 164, G : 7.52211332321167\n",
      "EPOCH : 2, step : 165, D : 7.4017252922058105\n",
      "EPOCH : 2, step : 166, G : 7.8181071281433105\n",
      "EPOCH : 2, step : 167, D : 7.45521354675293\n",
      "EPOCH : 2, step : 168, G : 7.406033515930176\n",
      "EPOCH : 2, step : 169, D : 7.428904056549072\n",
      "EPOCH : 2, step : 170, G : 7.502459526062012\n",
      "EPOCH : 2, step : 171, D : 7.495217800140381\n",
      "EPOCH : 2, step : 172, G : 8.346248626708984\n",
      "EPOCH : 2, step : 173, D : 7.344727516174316\n",
      "EPOCH : 2, step : 174, G : 7.517195224761963\n",
      "EPOCH : 2, step : 175, D : 7.353703022003174\n",
      "EPOCH : 2, step : 176, G : 8.089798927307129\n",
      "EPOCH : 2, step : 177, D : 7.378789901733398\n",
      "EPOCH : 2, step : 178, G : 7.4095635414123535\n",
      "EPOCH : 2, step : 179, D : 7.221601963043213\n",
      "EPOCH : 2, step : 180, G : 7.42626428604126\n",
      "EPOCH : 2, step : 181, D : 7.412076473236084\n",
      "EPOCH : 2, step : 182, G : 7.231860637664795\n",
      "EPOCH : 2, step : 183, D : 7.425347328186035\n",
      "EPOCH : 2, step : 184, G : 7.136504173278809\n",
      "EPOCH : 2, step : 185, D : 7.322534561157227\n",
      "EPOCH : 2, step : 186, G : 7.042852401733398\n",
      "EPOCH : 2, step : 187, D : 7.250036716461182\n",
      "EPOCH : 2, step : 188, G : 7.1476287841796875\n",
      "EPOCH : 2, step : 189, D : 7.344526767730713\n",
      "EPOCH : 2, step : 190, G : 7.1282830238342285\n",
      "EPOCH : 2, step : 191, D : 7.311392784118652\n",
      "EPOCH : 2, step : 192, G : 7.1891770362854\n",
      "EPOCH : 2, step : 193, D : 7.293205738067627\n",
      "EPOCH : 2, step : 194, G : 7.073242664337158\n",
      "EPOCH : 2, step : 195, D : 7.286707401275635\n",
      "EPOCH : 2, step : 196, G : 7.111856937408447\n",
      "EPOCH : 2, step : 197, D : 7.357407093048096\n",
      "EPOCH : 2, step : 198, G : 7.081477165222168\n",
      "EPOCH : 2, step : 199, D : 7.323546409606934\n",
      "EPOCH : 2, step : 200, G : 7.178989410400391\n",
      "EPOCH : 2, step : 201, D : 7.307272911071777\n",
      "EPOCH : 2, step : 202, G : 7.11284875869751\n",
      "EPOCH : 2, step : 203, D : 7.245126247406006\n",
      "EPOCH : 2, step : 204, G : 7.053102493286133\n",
      "EPOCH : 2, step : 205, D : 7.335049152374268\n",
      "EPOCH : 2, step : 206, G : 7.056065082550049\n",
      "EPOCH : 2, step : 207, D : 7.247383117675781\n",
      "EPOCH : 2, step : 208, G : 7.062215328216553\n",
      "EPOCH : 2, step : 209, D : 7.3349528312683105\n",
      "EPOCH : 2, step : 210, G : 7.07605504989624\n",
      "EPOCH : 2, step : 211, D : 7.346412181854248\n",
      "EPOCH : 2, step : 212, G : 7.065629482269287\n",
      "EPOCH : 2, step : 213, D : 7.299224376678467\n",
      "EPOCH : 2, step : 214, G : 7.057628631591797\n",
      "EPOCH : 2, step : 215, D : 7.319850444793701\n",
      "EPOCH : 2, step : 216, G : 7.100820541381836\n",
      "EPOCH : 2, step : 217, D : 7.302699565887451\n",
      "EPOCH : 2, step : 218, G : 7.0190277099609375\n",
      "EPOCH : 2, step : 219, D : 7.294010162353516\n",
      "EPOCH : 2, step : 220, G : 7.554098129272461\n",
      "EPOCH : 3, step : 221, D : 7.278642177581787\n",
      "EPOCH : 3, step : 222, G : 7.2719597816467285\n",
      "EPOCH : 3, step : 223, D : 7.182553291320801\n",
      "EPOCH : 3, step : 224, G : 7.058049201965332\n",
      "EPOCH : 3, step : 225, D : 7.152157306671143\n",
      "EPOCH : 3, step : 226, G : 7.0844621658325195\n",
      "EPOCH : 3, step : 227, D : 7.267463207244873\n",
      "EPOCH : 3, step : 228, G : 7.09070348739624\n",
      "EPOCH : 3, step : 229, D : 7.206356048583984\n",
      "EPOCH : 3, step : 230, G : 7.099279403686523\n",
      "EPOCH : 3, step : 231, D : 7.308966159820557\n",
      "EPOCH : 3, step : 232, G : 7.29909086227417\n",
      "EPOCH : 3, step : 233, D : 7.229315280914307\n",
      "EPOCH : 3, step : 234, G : 7.575488090515137\n",
      "EPOCH : 3, step : 235, D : 7.21441650390625\n",
      "EPOCH : 3, step : 236, G : 7.168117523193359\n",
      "EPOCH : 3, step : 237, D : 7.215662002563477\n",
      "EPOCH : 3, step : 238, G : 7.19348669052124\n",
      "EPOCH : 3, step : 239, D : 7.149377346038818\n",
      "EPOCH : 3, step : 240, G : 7.166454315185547\n",
      "EPOCH : 3, step : 241, D : 7.141891956329346\n",
      "EPOCH : 3, step : 242, G : 7.115983963012695\n",
      "EPOCH : 3, step : 243, D : 7.107105255126953\n",
      "EPOCH : 3, step : 244, G : 7.13835334777832\n",
      "EPOCH : 3, step : 245, D : 7.098662376403809\n",
      "EPOCH : 3, step : 246, G : 7.098406791687012\n",
      "EPOCH : 3, step : 247, D : 7.1408305168151855\n",
      "EPOCH : 3, step : 248, G : 7.113598823547363\n",
      "EPOCH : 3, step : 249, D : 7.024381637573242\n",
      "EPOCH : 3, step : 250, G : 7.093714714050293\n",
      "EPOCH : 3, step : 251, D : 7.219748020172119\n",
      "EPOCH : 3, step : 252, G : 7.004497528076172\n",
      "EPOCH : 3, step : 253, D : 7.09640645980835\n",
      "EPOCH : 3, step : 254, G : 7.072865962982178\n",
      "EPOCH : 3, step : 255, D : 7.138503551483154\n",
      "EPOCH : 3, step : 256, G : 7.3681745529174805\n",
      "EPOCH : 3, step : 257, D : 7.128588676452637\n",
      "EPOCH : 3, step : 258, G : 7.2605671882629395\n",
      "EPOCH : 3, step : 259, D : 7.143126964569092\n",
      "EPOCH : 3, step : 260, G : 7.1837358474731445\n",
      "EPOCH : 3, step : 261, D : 7.186342716217041\n",
      "EPOCH : 3, step : 262, G : 7.136321067810059\n",
      "EPOCH : 3, step : 263, D : 7.199423313140869\n",
      "EPOCH : 3, step : 264, G : 7.225543975830078\n",
      "EPOCH : 3, step : 265, D : 7.252274990081787\n",
      "EPOCH : 3, step : 266, G : 7.19346809387207\n",
      "EPOCH : 3, step : 267, D : 7.0181403160095215\n",
      "EPOCH : 3, step : 268, G : 7.169917106628418\n",
      "EPOCH : 3, step : 269, D : 7.101955413818359\n",
      "EPOCH : 3, step : 270, G : 7.110529899597168\n",
      "EPOCH : 3, step : 271, D : 7.147213459014893\n",
      "EPOCH : 3, step : 272, G : 7.385414123535156\n",
      "EPOCH : 3, step : 273, D : 6.94118595123291\n",
      "EPOCH : 3, step : 274, G : 7.629741191864014\n",
      "EPOCH : 3, step : 275, D : 7.107583999633789\n",
      "EPOCH : 3, step : 276, G : 7.231282711029053\n",
      "EPOCH : 3, step : 277, D : 6.959023475646973\n",
      "EPOCH : 3, step : 278, G : 7.293321132659912\n",
      "EPOCH : 3, step : 279, D : 7.026784420013428\n",
      "EPOCH : 3, step : 280, G : 7.239349842071533\n",
      "EPOCH : 3, step : 281, D : 7.079371452331543\n",
      "EPOCH : 3, step : 282, G : 7.170860290527344\n",
      "EPOCH : 3, step : 283, D : 7.000538349151611\n",
      "EPOCH : 3, step : 284, G : 7.192594528198242\n",
      "EPOCH : 3, step : 285, D : 6.984739303588867\n",
      "EPOCH : 3, step : 286, G : 7.185752868652344\n",
      "EPOCH : 3, step : 287, D : 6.959619998931885\n",
      "EPOCH : 3, step : 288, G : 7.2304768562316895\n",
      "EPOCH : 3, step : 289, D : 7.058995723724365\n",
      "EPOCH : 3, step : 290, G : 7.1340532302856445\n",
      "EPOCH : 3, step : 291, D : 7.0435967445373535\n",
      "EPOCH : 3, step : 292, G : 7.137723922729492\n",
      "EPOCH : 3, step : 293, D : 7.014941692352295\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 3, step : 294, G : 7.1057448387146\n",
      "EPOCH : 3, step : 295, D : 6.9707746505737305\n",
      "EPOCH : 3, step : 296, G : 7.13057279586792\n",
      "EPOCH : 3, step : 297, D : 7.112574577331543\n",
      "EPOCH : 3, step : 298, G : 7.185234546661377\n",
      "EPOCH : 3, step : 299, D : 7.038104057312012\n",
      "EPOCH : 3, step : 300, G : 7.12141752243042\n",
      "EPOCH : 3, step : 301, D : 6.946699142456055\n",
      "EPOCH : 3, step : 302, G : 7.1052045822143555\n",
      "EPOCH : 3, step : 303, D : 7.052834987640381\n",
      "EPOCH : 3, step : 304, G : 7.172644138336182\n",
      "EPOCH : 3, step : 305, D : 7.073223114013672\n",
      "EPOCH : 3, step : 306, G : 7.399919033050537\n",
      "EPOCH : 3, step : 307, D : 6.97652530670166\n",
      "EPOCH : 3, step : 308, G : 7.168344020843506\n",
      "EPOCH : 3, step : 309, D : 6.971804618835449\n",
      "EPOCH : 3, step : 310, G : 7.189900875091553\n",
      "EPOCH : 3, step : 311, D : 6.961858749389648\n",
      "EPOCH : 3, step : 312, G : 7.19865608215332\n",
      "EPOCH : 3, step : 313, D : 7.0014119148254395\n",
      "EPOCH : 3, step : 314, G : 7.19551944732666\n",
      "EPOCH : 3, step : 315, D : 6.955749034881592\n",
      "EPOCH : 3, step : 316, G : 7.189611434936523\n",
      "EPOCH : 3, step : 317, D : 6.938831806182861\n",
      "EPOCH : 3, step : 318, G : 7.1193461418151855\n",
      "EPOCH : 3, step : 319, D : 7.02089262008667\n",
      "EPOCH : 3, step : 320, G : 7.064187526702881\n",
      "EPOCH : 3, step : 321, D : 6.97136116027832\n",
      "EPOCH : 3, step : 322, G : 7.636934757232666\n",
      "EPOCH : 3, step : 323, D : 6.88051176071167\n",
      "EPOCH : 3, step : 324, G : 7.246051788330078\n",
      "EPOCH : 3, step : 325, D : 7.145090579986572\n",
      "EPOCH : 3, step : 326, G : 7.356645584106445\n",
      "EPOCH : 3, step : 327, D : 7.024325370788574\n",
      "EPOCH : 3, step : 328, G : 7.254987716674805\n",
      "EPOCH : 3, step : 329, D : 6.979875564575195\n",
      "EPOCH : 3, step : 330, G : 7.251420974731445\n",
      "EPOCH : 4, step : 331, D : 6.846994400024414\n",
      "EPOCH : 4, step : 332, G : 7.2184247970581055\n",
      "EPOCH : 4, step : 333, D : 6.843471527099609\n",
      "EPOCH : 4, step : 334, G : 7.27133321762085\n",
      "EPOCH : 4, step : 335, D : 6.7977986335754395\n",
      "EPOCH : 4, step : 336, G : 7.198640823364258\n",
      "EPOCH : 4, step : 337, D : 6.725009441375732\n",
      "EPOCH : 4, step : 338, G : 7.232537269592285\n",
      "EPOCH : 4, step : 339, D : 6.832559585571289\n",
      "EPOCH : 4, step : 340, G : 7.19551944732666\n",
      "EPOCH : 4, step : 341, D : 6.80492639541626\n",
      "EPOCH : 4, step : 342, G : 7.150164604187012\n",
      "EPOCH : 4, step : 343, D : 6.820131301879883\n",
      "EPOCH : 4, step : 344, G : 7.201893329620361\n",
      "EPOCH : 4, step : 345, D : 7.037381649017334\n",
      "EPOCH : 4, step : 346, G : 7.315404891967773\n",
      "EPOCH : 4, step : 347, D : 7.0771050453186035\n",
      "EPOCH : 4, step : 348, G : 7.191518306732178\n",
      "EPOCH : 4, step : 349, D : 6.842057228088379\n",
      "EPOCH : 4, step : 350, G : 7.198513031005859\n",
      "EPOCH : 4, step : 351, D : 6.934770584106445\n",
      "EPOCH : 4, step : 352, G : 7.2667765617370605\n",
      "EPOCH : 4, step : 353, D : 6.896669387817383\n",
      "EPOCH : 4, step : 354, G : 7.252011775970459\n",
      "EPOCH : 4, step : 355, D : 6.804317951202393\n",
      "EPOCH : 4, step : 356, G : 7.213666915893555\n",
      "EPOCH : 4, step : 357, D : 6.827214241027832\n",
      "EPOCH : 4, step : 358, G : 7.2247209548950195\n",
      "EPOCH : 4, step : 359, D : 6.822807788848877\n",
      "EPOCH : 4, step : 360, G : 7.131744861602783\n",
      "EPOCH : 4, step : 361, D : 6.959700584411621\n",
      "EPOCH : 4, step : 362, G : 7.219918251037598\n",
      "EPOCH : 4, step : 363, D : 7.127153396606445\n",
      "EPOCH : 4, step : 364, G : 7.009210586547852\n",
      "EPOCH : 4, step : 365, D : 7.040777206420898\n",
      "EPOCH : 4, step : 366, G : 7.168184280395508\n",
      "EPOCH : 4, step : 367, D : 7.086617946624756\n",
      "EPOCH : 4, step : 368, G : 7.8665595054626465\n",
      "EPOCH : 4, step : 369, D : 7.3525519371032715\n",
      "EPOCH : 4, step : 370, G : 7.3825249671936035\n",
      "EPOCH : 4, step : 371, D : 7.2822699546813965\n",
      "EPOCH : 4, step : 372, G : 7.3206000328063965\n",
      "EPOCH : 4, step : 373, D : 7.0868425369262695\n",
      "EPOCH : 4, step : 374, G : 7.29428243637085\n",
      "EPOCH : 4, step : 375, D : 7.405298233032227\n",
      "EPOCH : 4, step : 376, G : 7.296609878540039\n",
      "EPOCH : 4, step : 377, D : 7.250270366668701\n",
      "EPOCH : 4, step : 378, G : 7.3982439041137695\n",
      "EPOCH : 4, step : 379, D : 7.474874973297119\n",
      "EPOCH : 4, step : 380, G : 7.4264068603515625\n",
      "EPOCH : 4, step : 381, D : 7.676826477050781\n",
      "EPOCH : 4, step : 382, G : 7.334794998168945\n",
      "EPOCH : 4, step : 383, D : 6.984885215759277\n",
      "EPOCH : 4, step : 384, G : 7.222000598907471\n",
      "EPOCH : 4, step : 385, D : 6.987155914306641\n",
      "EPOCH : 4, step : 386, G : 7.233702659606934\n",
      "EPOCH : 4, step : 387, D : 7.244604110717773\n",
      "EPOCH : 4, step : 388, G : 7.22336483001709\n",
      "EPOCH : 4, step : 389, D : 7.013994216918945\n",
      "EPOCH : 4, step : 390, G : 7.339372634887695\n",
      "EPOCH : 4, step : 391, D : 7.09141206741333\n",
      "EPOCH : 4, step : 392, G : 7.233026504516602\n",
      "EPOCH : 4, step : 393, D : 6.984018325805664\n",
      "EPOCH : 4, step : 394, G : 7.102715492248535\n",
      "EPOCH : 4, step : 395, D : 6.800661087036133\n",
      "EPOCH : 4, step : 396, G : 7.1286773681640625\n",
      "EPOCH : 4, step : 397, D : 6.895961284637451\n",
      "EPOCH : 4, step : 398, G : 7.309351444244385\n",
      "EPOCH : 4, step : 399, D : 6.9372477531433105\n",
      "EPOCH : 4, step : 400, G : 7.232476711273193\n",
      "EPOCH : 4, step : 401, D : 6.944697856903076\n",
      "EPOCH : 4, step : 402, G : 7.171613693237305\n",
      "EPOCH : 4, step : 403, D : 6.960887432098389\n",
      "EPOCH : 4, step : 404, G : 7.391684055328369\n",
      "EPOCH : 4, step : 405, D : 7.114453315734863\n",
      "EPOCH : 4, step : 406, G : 7.943551063537598\n",
      "EPOCH : 4, step : 407, D : 7.109316349029541\n",
      "EPOCH : 4, step : 408, G : 7.264766216278076\n",
      "EPOCH : 4, step : 409, D : 7.167937755584717\n",
      "EPOCH : 4, step : 410, G : 7.3389668464660645\n",
      "EPOCH : 4, step : 411, D : 6.985325813293457\n",
      "EPOCH : 4, step : 412, G : 7.252710342407227\n",
      "EPOCH : 4, step : 413, D : 6.756102085113525\n",
      "EPOCH : 4, step : 414, G : 7.484997749328613\n",
      "EPOCH : 4, step : 415, D : 6.800189971923828\n",
      "EPOCH : 4, step : 416, G : 7.23403263092041\n",
      "EPOCH : 4, step : 417, D : 6.792194366455078\n",
      "EPOCH : 4, step : 418, G : 7.205572605133057\n",
      "EPOCH : 4, step : 419, D : 6.880550861358643\n",
      "EPOCH : 4, step : 420, G : 7.193195819854736\n",
      "EPOCH : 4, step : 421, D : 6.87855863571167\n",
      "EPOCH : 4, step : 422, G : 7.133917808532715\n",
      "EPOCH : 4, step : 423, D : 7.020092964172363\n",
      "EPOCH : 4, step : 424, G : 7.269145965576172\n",
      "EPOCH : 4, step : 425, D : 6.788560390472412\n",
      "EPOCH : 4, step : 426, G : 7.164875030517578\n",
      "EPOCH : 4, step : 427, D : 6.8508405685424805\n",
      "EPOCH : 4, step : 428, G : 7.139801502227783\n",
      "EPOCH : 4, step : 429, D : 6.959529399871826\n",
      "EPOCH : 4, step : 430, G : 7.183173656463623\n",
      "EPOCH : 4, step : 432, G : 7.121264457702637\n",
      "EPOCH : 4, step : 433, D : 6.790518283843994\n",
      "EPOCH : 4, step : 434, G : 7.219233512878418\n",
      "EPOCH : 4, step : 435, D : 6.830836772918701\n",
      "EPOCH : 4, step : 436, G : 7.28926944732666\n",
      "EPOCH : 4, step : 437, D : 6.836341381072998\n",
      "EPOCH : 4, step : 438, G : 7.184991836547852\n",
      "EPOCH : 4, step : 439, D : 6.893994331359863\n",
      "EPOCH : 4, step : 440, G : 7.309526443481445\n",
      "EPOCH : 5, step : 441, D : 6.890646934509277\n",
      "EPOCH : 5, step : 442, G : 7.195743560791016\n",
      "EPOCH : 5, step : 443, D : 6.708131790161133\n",
      "EPOCH : 5, step : 444, G : 7.097513198852539\n",
      "EPOCH : 5, step : 445, D : 6.739983558654785\n",
      "EPOCH : 5, step : 446, G : 7.206951141357422\n",
      "EPOCH : 5, step : 447, D : 6.820223331451416\n",
      "EPOCH : 5, step : 448, G : 7.075922012329102\n",
      "EPOCH : 5, step : 449, D : 6.785482883453369\n",
      "EPOCH : 5, step : 450, G : 7.150485515594482\n",
      "EPOCH : 5, step : 451, D : 6.624969005584717\n",
      "EPOCH : 5, step : 452, G : 7.172459125518799\n",
      "EPOCH : 5, step : 453, D : 6.668646812438965\n",
      "EPOCH : 5, step : 454, G : 7.14849328994751\n",
      "EPOCH : 5, step : 455, D : 6.576991081237793\n",
      "EPOCH : 5, step : 456, G : 7.250899314880371\n",
      "EPOCH : 5, step : 457, D : 6.671485424041748\n",
      "EPOCH : 5, step : 458, G : 7.061180114746094\n",
      "EPOCH : 5, step : 459, D : 6.785358905792236\n",
      "EPOCH : 5, step : 460, G : 7.169910907745361\n",
      "EPOCH : 5, step : 461, D : 6.886963844299316\n",
      "EPOCH : 5, step : 462, G : 7.106142520904541\n",
      "EPOCH : 5, step : 463, D : 6.735917568206787\n",
      "EPOCH : 5, step : 464, G : 7.201409339904785\n",
      "EPOCH : 5, step : 465, D : 6.78508186340332\n",
      "EPOCH : 5, step : 466, G : 7.2002482414245605\n",
      "EPOCH : 5, step : 467, D : 6.7281084060668945\n",
      "EPOCH : 5, step : 468, G : 7.234858989715576\n",
      "EPOCH : 5, step : 469, D : 6.565241813659668\n",
      "EPOCH : 5, step : 470, G : 7.235992908477783\n",
      "EPOCH : 5, step : 471, D : 6.643800258636475\n",
      "EPOCH : 5, step : 472, G : 7.222833156585693\n",
      "EPOCH : 5, step : 473, D : 6.679276943206787\n",
      "EPOCH : 5, step : 474, G : 7.092014789581299\n",
      "EPOCH : 5, step : 475, D : 6.644436359405518\n",
      "EPOCH : 5, step : 476, G : 7.308710098266602\n",
      "EPOCH : 5, step : 477, D : 6.727725505828857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 5, step : 478, G : 7.211894512176514\n",
      "EPOCH : 5, step : 479, D : 6.682022571563721\n",
      "EPOCH : 5, step : 480, G : 7.23668909072876\n",
      "EPOCH : 5, step : 481, D : 6.778932094573975\n",
      "EPOCH : 5, step : 482, G : 7.169198989868164\n",
      "EPOCH : 5, step : 483, D : 6.781635284423828\n",
      "EPOCH : 5, step : 484, G : 7.182280540466309\n",
      "EPOCH : 5, step : 485, D : 6.661975383758545\n",
      "EPOCH : 5, step : 486, G : 7.153035640716553\n",
      "EPOCH : 5, step : 487, D : 6.615057468414307\n",
      "EPOCH : 5, step : 488, G : 7.30815315246582\n",
      "EPOCH : 5, step : 489, D : 6.507323265075684\n",
      "EPOCH : 5, step : 490, G : 7.206066131591797\n",
      "EPOCH : 5, step : 491, D : 6.710513114929199\n",
      "EPOCH : 5, step : 492, G : 7.195493698120117\n",
      "EPOCH : 5, step : 493, D : 6.5861382484436035\n",
      "EPOCH : 5, step : 494, G : 7.179818153381348\n",
      "EPOCH : 5, step : 495, D : 6.610709190368652\n",
      "EPOCH : 5, step : 496, G : 7.12639045715332\n",
      "EPOCH : 5, step : 497, D : 6.634424686431885\n",
      "EPOCH : 5, step : 498, G : 7.158304214477539\n",
      "EPOCH : 5, step : 499, D : 6.714442253112793\n",
      "EPOCH : 5, step : 500, G : 7.224498748779297\n",
      "EPOCH : 5, step : 501, D : 6.666594982147217\n",
      "EPOCH : 5, step : 502, G : 7.180456161499023\n",
      "EPOCH : 5, step : 503, D : 6.525607585906982\n",
      "EPOCH : 5, step : 504, G : 7.265784740447998\n",
      "EPOCH : 5, step : 505, D : 6.657334327697754\n",
      "EPOCH : 5, step : 506, G : 7.236954689025879\n",
      "EPOCH : 5, step : 507, D : 6.537464618682861\n",
      "EPOCH : 5, step : 508, G : 7.34237813949585\n",
      "EPOCH : 5, step : 509, D : 6.537392616271973\n",
      "EPOCH : 5, step : 510, G : 7.24488639831543\n",
      "EPOCH : 5, step : 511, D : 6.5850348472595215\n",
      "EPOCH : 5, step : 512, G : 7.295328617095947\n",
      "EPOCH : 5, step : 513, D : 6.702216148376465\n",
      "EPOCH : 5, step : 514, G : 7.253180980682373\n",
      "EPOCH : 5, step : 515, D : 6.526541233062744\n",
      "EPOCH : 5, step : 516, G : 7.131927490234375\n",
      "EPOCH : 5, step : 517, D : 6.60697078704834\n",
      "EPOCH : 5, step : 518, G : 7.285763740539551\n",
      "EPOCH : 5, step : 519, D : 6.652698040008545\n",
      "EPOCH : 5, step : 520, G : 7.16682243347168\n",
      "EPOCH : 5, step : 521, D : 6.67111349105835\n",
      "EPOCH : 5, step : 522, G : 7.241968154907227\n",
      "EPOCH : 5, step : 523, D : 6.852684497833252\n",
      "EPOCH : 5, step : 524, G : 7.250227451324463\n",
      "EPOCH : 5, step : 525, D : 6.730780601501465\n",
      "EPOCH : 5, step : 526, G : 7.328213214874268\n",
      "EPOCH : 5, step : 527, D : 6.589181423187256\n",
      "EPOCH : 5, step : 528, G : 7.255836009979248\n",
      "EPOCH : 5, step : 529, D : 6.629071235656738\n",
      "EPOCH : 5, step : 530, G : 7.238944053649902\n",
      "EPOCH : 5, step : 531, D : 6.550992488861084\n",
      "EPOCH : 5, step : 532, G : 7.244720458984375\n",
      "EPOCH : 5, step : 533, D : 6.562315464019775\n",
      "EPOCH : 5, step : 534, G : 7.3180084228515625\n",
      "EPOCH : 5, step : 535, D : 6.590531349182129\n",
      "EPOCH : 5, step : 536, G : 7.109145164489746\n",
      "EPOCH : 5, step : 537, D : 6.661434650421143\n",
      "EPOCH : 5, step : 538, G : 7.372684001922607\n",
      "EPOCH : 5, step : 539, D : 6.838397979736328\n",
      "EPOCH : 5, step : 540, G : 6.745666980743408\n",
      "EPOCH : 5, step : 541, D : 7.105751037597656\n",
      "EPOCH : 5, step : 542, G : 6.5233988761901855\n",
      "EPOCH : 5, step : 543, D : 7.1055588722229\n",
      "EPOCH : 5, step : 544, G : 6.7506842613220215\n",
      "EPOCH : 5, step : 545, D : 6.9385199546813965\n",
      "EPOCH : 5, step : 546, G : 6.911965847015381\n",
      "EPOCH : 5, step : 547, D : 6.813645839691162\n",
      "EPOCH : 5, step : 548, G : 6.8562703132629395\n",
      "EPOCH : 5, step : 549, D : 6.858990669250488\n",
      "EPOCH : 5, step : 550, G : 6.848450660705566\n",
      "EPOCH : 6, step : 551, D : 6.752068519592285\n",
      "EPOCH : 6, step : 552, G : 6.9099578857421875\n",
      "EPOCH : 6, step : 553, D : 6.799344539642334\n",
      "EPOCH : 6, step : 554, G : 6.99193000793457\n",
      "EPOCH : 6, step : 555, D : 6.7142791748046875\n",
      "EPOCH : 6, step : 556, G : 7.094040870666504\n",
      "EPOCH : 6, step : 557, D : 6.599664688110352\n",
      "EPOCH : 6, step : 558, G : 6.83696174621582\n",
      "EPOCH : 6, step : 559, D : 6.686399459838867\n",
      "EPOCH : 6, step : 560, G : 6.854704856872559\n",
      "EPOCH : 6, step : 561, D : 6.636350631713867\n",
      "EPOCH : 6, step : 562, G : 7.012762069702148\n",
      "EPOCH : 6, step : 563, D : 6.833356857299805\n",
      "EPOCH : 6, step : 564, G : 7.021975517272949\n",
      "EPOCH : 6, step : 565, D : 6.640298366546631\n",
      "EPOCH : 6, step : 566, G : 6.952258110046387\n",
      "EPOCH : 6, step : 567, D : 6.647213935852051\n",
      "EPOCH : 6, step : 568, G : 6.9922943115234375\n",
      "EPOCH : 6, step : 569, D : 6.731898784637451\n",
      "EPOCH : 6, step : 570, G : 6.88284158706665\n",
      "EPOCH : 6, step : 571, D : 6.681270599365234\n",
      "EPOCH : 6, step : 572, G : 7.047571182250977\n",
      "EPOCH : 6, step : 573, D : 6.843329906463623\n",
      "EPOCH : 6, step : 574, G : 7.350699424743652\n",
      "EPOCH : 6, step : 575, D : 6.727285385131836\n",
      "EPOCH : 6, step : 576, G : 7.054629325866699\n",
      "EPOCH : 6, step : 577, D : 6.563863754272461\n",
      "EPOCH : 6, step : 578, G : 6.9466071128845215\n",
      "EPOCH : 6, step : 579, D : 6.559237003326416\n",
      "EPOCH : 6, step : 580, G : 7.1063642501831055\n",
      "EPOCH : 6, step : 581, D : 6.524953365325928\n",
      "EPOCH : 6, step : 582, G : 6.9860124588012695\n",
      "EPOCH : 6, step : 583, D : 6.4458088874816895\n",
      "EPOCH : 6, step : 584, G : 7.158474445343018\n",
      "EPOCH : 6, step : 585, D : 6.636170387268066\n",
      "EPOCH : 6, step : 586, G : 6.970907211303711\n",
      "EPOCH : 6, step : 587, D : 6.747797012329102\n",
      "EPOCH : 6, step : 588, G : 7.016560077667236\n",
      "EPOCH : 6, step : 589, D : 6.68608283996582\n",
      "EPOCH : 6, step : 590, G : 7.183393955230713\n",
      "EPOCH : 6, step : 591, D : 6.695984840393066\n",
      "EPOCH : 6, step : 592, G : 7.124453544616699\n",
      "EPOCH : 6, step : 593, D : 6.538230895996094\n",
      "EPOCH : 6, step : 594, G : 7.11608362197876\n",
      "EPOCH : 6, step : 595, D : 6.525689125061035\n",
      "EPOCH : 6, step : 596, G : 7.089751243591309\n",
      "EPOCH : 6, step : 597, D : 6.508086204528809\n",
      "EPOCH : 6, step : 598, G : 7.067226409912109\n",
      "EPOCH : 6, step : 599, D : 6.755897521972656\n",
      "EPOCH : 6, step : 600, G : 7.124603271484375\n",
      "EPOCH : 6, step : 601, D : 6.8739166259765625\n",
      "EPOCH : 6, step : 602, G : 6.892727375030518\n",
      "EPOCH : 6, step : 603, D : 6.8329081535339355\n",
      "EPOCH : 6, step : 604, G : 6.948158264160156\n",
      "EPOCH : 6, step : 605, D : 6.6220703125\n",
      "EPOCH : 6, step : 606, G : 6.98282527923584\n",
      "EPOCH : 6, step : 607, D : 6.7168073654174805\n",
      "EPOCH : 6, step : 608, G : 6.745199680328369\n",
      "EPOCH : 6, step : 609, D : 7.039659023284912\n",
      "EPOCH : 6, step : 610, G : 6.460771560668945\n",
      "EPOCH : 6, step : 611, D : 7.099351406097412\n",
      "EPOCH : 6, step : 612, G : 6.775606155395508\n",
      "EPOCH : 6, step : 613, D : 6.996859073638916\n",
      "EPOCH : 6, step : 614, G : 6.757772922515869\n",
      "EPOCH : 6, step : 615, D : 6.915206432342529\n",
      "EPOCH : 6, step : 616, G : 6.983968734741211\n",
      "EPOCH : 6, step : 617, D : 7.0120158195495605\n",
      "EPOCH : 6, step : 618, G : 7.235531330108643\n",
      "EPOCH : 6, step : 619, D : 6.898078441619873\n",
      "EPOCH : 6, step : 620, G : 6.96492338180542\n",
      "EPOCH : 6, step : 621, D : 6.987973690032959\n",
      "EPOCH : 6, step : 622, G : 7.254169464111328\n",
      "EPOCH : 6, step : 623, D : 6.774940490722656\n",
      "EPOCH : 6, step : 624, G : 7.679714202880859\n",
      "EPOCH : 6, step : 625, D : 6.662407875061035\n",
      "EPOCH : 6, step : 626, G : 7.167395114898682\n",
      "EPOCH : 6, step : 627, D : 6.618934154510498\n",
      "EPOCH : 6, step : 628, G : 7.010004043579102\n",
      "EPOCH : 6, step : 629, D : 6.728936195373535\n",
      "EPOCH : 6, step : 630, G : 7.03817081451416\n",
      "EPOCH : 6, step : 631, D : 6.786435604095459\n",
      "EPOCH : 6, step : 632, G : 7.160356044769287\n",
      "EPOCH : 6, step : 633, D : 6.833722114562988\n",
      "EPOCH : 6, step : 634, G : 6.710758209228516\n",
      "EPOCH : 6, step : 635, D : 6.951039791107178\n",
      "EPOCH : 6, step : 636, G : 6.806914806365967\n",
      "EPOCH : 6, step : 637, D : 6.818709373474121\n",
      "EPOCH : 6, step : 638, G : 7.087829113006592\n",
      "EPOCH : 6, step : 639, D : 6.872994422912598\n",
      "EPOCH : 6, step : 640, G : 6.988023281097412\n",
      "EPOCH : 6, step : 641, D : 6.704128265380859\n",
      "EPOCH : 6, step : 642, G : 6.764081954956055\n",
      "EPOCH : 6, step : 643, D : 7.118628978729248\n",
      "EPOCH : 6, step : 644, G : 6.976207256317139\n",
      "EPOCH : 6, step : 645, D : 6.876906871795654\n",
      "EPOCH : 6, step : 646, G : 7.375080585479736\n",
      "EPOCH : 6, step : 647, D : 6.744141101837158\n",
      "EPOCH : 6, step : 648, G : 6.5999369621276855\n",
      "EPOCH : 6, step : 649, D : 6.739109992980957\n",
      "EPOCH : 6, step : 650, G : 6.873321533203125\n",
      "EPOCH : 6, step : 651, D : 6.556091785430908\n",
      "EPOCH : 6, step : 652, G : 7.012923717498779\n",
      "EPOCH : 6, step : 653, D : 6.79021692276001\n",
      "EPOCH : 6, step : 654, G : 7.092101573944092\n",
      "EPOCH : 6, step : 655, D : 6.73015832901001\n",
      "EPOCH : 6, step : 656, G : 6.893077373504639\n",
      "EPOCH : 6, step : 657, D : 6.785310745239258\n",
      "EPOCH : 6, step : 658, G : 7.12434196472168\n",
      "EPOCH : 6, step : 659, D : 6.831262111663818\n",
      "EPOCH : 6, step : 660, G : 7.0361785888671875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 7, step : 661, D : 6.79098653793335\n",
      "EPOCH : 7, step : 662, G : 6.992258071899414\n",
      "EPOCH : 7, step : 663, D : 6.583299160003662\n",
      "EPOCH : 7, step : 664, G : 6.991307258605957\n",
      "EPOCH : 7, step : 665, D : 6.671349048614502\n",
      "EPOCH : 7, step : 666, G : 6.880144119262695\n",
      "EPOCH : 7, step : 667, D : 6.72780704498291\n",
      "EPOCH : 7, step : 668, G : 6.901692867279053\n",
      "EPOCH : 7, step : 669, D : 6.670871257781982\n",
      "EPOCH : 7, step : 670, G : 6.972987174987793\n",
      "EPOCH : 7, step : 671, D : 6.487018585205078\n",
      "EPOCH : 7, step : 672, G : 7.0492730140686035\n",
      "EPOCH : 7, step : 673, D : 6.6367011070251465\n",
      "EPOCH : 7, step : 674, G : 7.142626762390137\n",
      "EPOCH : 7, step : 675, D : 6.4650959968566895\n",
      "EPOCH : 7, step : 676, G : 7.014721870422363\n",
      "EPOCH : 7, step : 677, D : 6.475342750549316\n",
      "EPOCH : 7, step : 678, G : 7.09406042098999\n",
      "EPOCH : 7, step : 679, D : 6.575969696044922\n",
      "EPOCH : 7, step : 680, G : 6.941701412200928\n",
      "EPOCH : 7, step : 681, D : 6.604556083679199\n",
      "EPOCH : 7, step : 682, G : 7.110828876495361\n",
      "EPOCH : 7, step : 683, D : 6.778003215789795\n",
      "EPOCH : 7, step : 684, G : 7.040831089019775\n",
      "EPOCH : 7, step : 685, D : 6.696746349334717\n",
      "EPOCH : 7, step : 686, G : 6.931316375732422\n",
      "EPOCH : 7, step : 687, D : 6.6965227127075195\n",
      "EPOCH : 7, step : 688, G : 6.978561878204346\n",
      "EPOCH : 7, step : 689, D : 6.677846908569336\n",
      "EPOCH : 7, step : 690, G : 6.937633991241455\n",
      "EPOCH : 7, step : 691, D : 6.624530792236328\n",
      "EPOCH : 7, step : 692, G : 6.95613431930542\n",
      "EPOCH : 7, step : 693, D : 6.543481349945068\n",
      "EPOCH : 7, step : 694, G : 6.883985996246338\n",
      "EPOCH : 7, step : 695, D : 6.61890172958374\n",
      "EPOCH : 7, step : 696, G : 7.157647132873535\n",
      "EPOCH : 7, step : 697, D : 6.55007791519165\n",
      "EPOCH : 7, step : 698, G : 6.937329292297363\n",
      "EPOCH : 7, step : 699, D : 6.6525397300720215\n",
      "EPOCH : 7, step : 700, G : 7.02008581161499\n",
      "EPOCH : 7, step : 701, D : 6.564417839050293\n",
      "EPOCH : 7, step : 702, G : 7.020196914672852\n",
      "EPOCH : 7, step : 703, D : 6.455657005310059\n",
      "EPOCH : 7, step : 704, G : 6.938534736633301\n",
      "EPOCH : 7, step : 705, D : 6.758755683898926\n",
      "EPOCH : 7, step : 706, G : 7.065040111541748\n",
      "EPOCH : 7, step : 707, D : 6.503740310668945\n",
      "EPOCH : 7, step : 708, G : 7.13469123840332\n",
      "EPOCH : 7, step : 709, D : 6.707596302032471\n",
      "EPOCH : 7, step : 710, G : 6.9049296379089355\n",
      "EPOCH : 7, step : 711, D : 6.585781574249268\n",
      "EPOCH : 7, step : 712, G : 6.948598384857178\n",
      "EPOCH : 7, step : 713, D : 6.529280662536621\n",
      "EPOCH : 7, step : 714, G : 7.315854072570801\n",
      "EPOCH : 7, step : 715, D : 6.616979122161865\n",
      "EPOCH : 7, step : 716, G : 7.139575481414795\n",
      "EPOCH : 7, step : 717, D : 6.515131950378418\n",
      "EPOCH : 7, step : 718, G : 6.939213275909424\n",
      "EPOCH : 7, step : 719, D : 6.696422100067139\n",
      "EPOCH : 7, step : 720, G : 7.132850646972656\n",
      "EPOCH : 7, step : 721, D : 6.712714195251465\n",
      "EPOCH : 7, step : 722, G : 7.041215419769287\n",
      "EPOCH : 7, step : 723, D : 6.623328685760498\n",
      "EPOCH : 7, step : 724, G : 7.003154754638672\n",
      "EPOCH : 7, step : 725, D : 6.435783863067627\n",
      "EPOCH : 7, step : 726, G : 7.057149887084961\n",
      "EPOCH : 7, step : 727, D : 6.549720287322998\n",
      "EPOCH : 7, step : 728, G : 7.145182132720947\n",
      "EPOCH : 7, step : 729, D : 6.618978500366211\n",
      "EPOCH : 7, step : 730, G : 6.881634712219238\n",
      "EPOCH : 7, step : 731, D : 6.48431921005249\n",
      "EPOCH : 7, step : 732, G : 6.954765796661377\n",
      "EPOCH : 7, step : 733, D : 6.54396915435791\n",
      "EPOCH : 7, step : 734, G : 7.005029201507568\n",
      "EPOCH : 7, step : 735, D : 6.403878211975098\n",
      "EPOCH : 7, step : 736, G : 6.805425643920898\n",
      "EPOCH : 7, step : 737, D : 6.461370944976807\n",
      "EPOCH : 7, step : 738, G : 6.960762977600098\n",
      "EPOCH : 7, step : 739, D : 6.373111724853516\n",
      "EPOCH : 7, step : 740, G : 6.970438003540039\n",
      "EPOCH : 7, step : 741, D : 6.520742893218994\n",
      "EPOCH : 7, step : 742, G : 6.847761154174805\n",
      "EPOCH : 7, step : 743, D : 6.424554347991943\n",
      "EPOCH : 7, step : 744, G : 7.0701422691345215\n",
      "EPOCH : 7, step : 745, D : 6.5033979415893555\n",
      "EPOCH : 7, step : 746, G : 6.694248199462891\n",
      "EPOCH : 7, step : 747, D : 6.835890293121338\n",
      "EPOCH : 7, step : 748, G : 6.921797752380371\n",
      "EPOCH : 7, step : 749, D : 6.704751968383789\n",
      "EPOCH : 7, step : 750, G : 6.846647262573242\n",
      "EPOCH : 7, step : 751, D : 6.496946334838867\n",
      "EPOCH : 7, step : 752, G : 6.86552619934082\n",
      "EPOCH : 7, step : 753, D : 6.526560306549072\n",
      "EPOCH : 7, step : 754, G : 7.138411521911621\n",
      "EPOCH : 7, step : 755, D : 6.759031772613525\n",
      "EPOCH : 7, step : 756, G : 6.863138198852539\n",
      "EPOCH : 7, step : 757, D : 6.733254432678223\n",
      "EPOCH : 7, step : 758, G : 7.115596771240234\n",
      "EPOCH : 7, step : 759, D : 6.817253589630127\n",
      "EPOCH : 7, step : 760, G : 6.838104248046875\n",
      "EPOCH : 7, step : 761, D : 6.675323963165283\n",
      "EPOCH : 7, step : 762, G : 6.983750343322754\n",
      "EPOCH : 7, step : 763, D : 6.596759796142578\n",
      "EPOCH : 7, step : 764, G : 7.285531520843506\n",
      "EPOCH : 7, step : 765, D : 6.5137763023376465\n",
      "EPOCH : 7, step : 766, G : 6.980592727661133\n",
      "EPOCH : 7, step : 767, D : 6.513645172119141\n",
      "EPOCH : 7, step : 768, G : 7.0403265953063965\n",
      "EPOCH : 7, step : 769, D : 6.5858988761901855\n",
      "EPOCH : 7, step : 770, G : 6.831053733825684\n",
      "EPOCH : 8, step : 771, D : 6.462188243865967\n",
      "EPOCH : 8, step : 772, G : 7.089855194091797\n",
      "EPOCH : 8, step : 773, D : 6.509231090545654\n",
      "EPOCH : 8, step : 774, G : 6.639254093170166\n",
      "EPOCH : 8, step : 775, D : 6.75136137008667\n",
      "EPOCH : 8, step : 776, G : 7.015356540679932\n",
      "EPOCH : 8, step : 777, D : 6.469209671020508\n",
      "EPOCH : 8, step : 778, G : 6.979168891906738\n",
      "EPOCH : 8, step : 779, D : 6.644686222076416\n",
      "EPOCH : 8, step : 780, G : 6.628063678741455\n",
      "EPOCH : 8, step : 781, D : 6.495310306549072\n",
      "EPOCH : 8, step : 782, G : 6.940648078918457\n",
      "EPOCH : 8, step : 783, D : 6.6490020751953125\n",
      "EPOCH : 8, step : 784, G : 6.935720443725586\n",
      "EPOCH : 8, step : 785, D : 6.390135288238525\n",
      "EPOCH : 8, step : 786, G : 6.92626953125\n",
      "EPOCH : 8, step : 787, D : 6.419980525970459\n",
      "EPOCH : 8, step : 788, G : 6.935103893280029\n",
      "EPOCH : 8, step : 789, D : 6.512462139129639\n",
      "EPOCH : 8, step : 790, G : 7.1791181564331055\n",
      "EPOCH : 8, step : 791, D : 6.387948036193848\n",
      "EPOCH : 8, step : 792, G : 6.781521320343018\n",
      "EPOCH : 8, step : 793, D : 6.463061332702637\n",
      "EPOCH : 8, step : 794, G : 7.1621012687683105\n",
      "EPOCH : 8, step : 795, D : 6.762282848358154\n",
      "EPOCH : 8, step : 796, G : 6.609360694885254\n",
      "EPOCH : 8, step : 797, D : 6.842668533325195\n",
      "EPOCH : 8, step : 798, G : 6.690402984619141\n",
      "EPOCH : 8, step : 799, D : 6.685122013092041\n",
      "EPOCH : 8, step : 800, G : 6.9301886558532715\n",
      "EPOCH : 8, step : 801, D : 6.522271156311035\n",
      "EPOCH : 8, step : 802, G : 6.638185977935791\n",
      "EPOCH : 8, step : 803, D : 6.3741326332092285\n",
      "EPOCH : 8, step : 804, G : 7.110185623168945\n",
      "EPOCH : 8, step : 805, D : 6.648507118225098\n",
      "EPOCH : 8, step : 806, G : 6.9301934242248535\n",
      "EPOCH : 8, step : 807, D : 6.393088340759277\n",
      "EPOCH : 8, step : 808, G : 7.24747371673584\n",
      "EPOCH : 8, step : 809, D : 6.479663372039795\n",
      "EPOCH : 8, step : 810, G : 7.192187786102295\n",
      "EPOCH : 8, step : 811, D : 6.516869068145752\n",
      "EPOCH : 8, step : 812, G : 7.000444412231445\n",
      "EPOCH : 8, step : 813, D : 6.375682830810547\n",
      "EPOCH : 8, step : 814, G : 7.251194953918457\n",
      "EPOCH : 8, step : 815, D : 6.409313201904297\n",
      "EPOCH : 8, step : 816, G : 6.85743522644043\n",
      "EPOCH : 8, step : 817, D : 6.634796619415283\n",
      "EPOCH : 8, step : 818, G : 6.975002288818359\n",
      "EPOCH : 8, step : 819, D : 6.5005292892456055\n",
      "EPOCH : 8, step : 820, G : 7.01478385925293\n",
      "EPOCH : 8, step : 821, D : 6.528224945068359\n",
      "EPOCH : 8, step : 822, G : 6.846944808959961\n",
      "EPOCH : 8, step : 823, D : 6.649962425231934\n",
      "EPOCH : 8, step : 824, G : 6.758238792419434\n",
      "EPOCH : 8, step : 825, D : 6.531347274780273\n",
      "EPOCH : 8, step : 826, G : 7.079377174377441\n",
      "EPOCH : 8, step : 827, D : 6.507041931152344\n",
      "EPOCH : 8, step : 828, G : 6.972082614898682\n",
      "EPOCH : 8, step : 829, D : 6.492222309112549\n",
      "EPOCH : 8, step : 830, G : 7.125190258026123\n",
      "EPOCH : 8, step : 831, D : 6.415983200073242\n",
      "EPOCH : 8, step : 832, G : 7.054193019866943\n",
      "EPOCH : 8, step : 833, D : 6.407092094421387\n",
      "EPOCH : 8, step : 834, G : 7.151782035827637\n",
      "EPOCH : 8, step : 835, D : 6.605703830718994\n",
      "EPOCH : 8, step : 836, G : 6.760669231414795\n",
      "EPOCH : 8, step : 837, D : 6.570940971374512\n",
      "EPOCH : 8, step : 838, G : 7.092370986938477\n",
      "EPOCH : 8, step : 839, D : 6.3757452964782715\n",
      "EPOCH : 8, step : 840, G : 7.206511497497559\n",
      "EPOCH : 8, step : 841, D : 6.37866735458374\n",
      "EPOCH : 8, step : 842, G : 6.828914642333984\n",
      "EPOCH : 8, step : 843, D : 6.643094539642334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 8, step : 844, G : 6.840269565582275\n",
      "EPOCH : 8, step : 845, D : 6.407989025115967\n",
      "EPOCH : 8, step : 846, G : 6.873669147491455\n",
      "EPOCH : 8, step : 847, D : 6.6183180809021\n",
      "EPOCH : 8, step : 848, G : 7.121105194091797\n",
      "EPOCH : 8, step : 849, D : 6.41027307510376\n",
      "EPOCH : 8, step : 850, G : 6.903271675109863\n",
      "EPOCH : 8, step : 851, D : 6.490921974182129\n",
      "EPOCH : 8, step : 852, G : 6.938608646392822\n",
      "EPOCH : 8, step : 853, D : 6.432162284851074\n",
      "EPOCH : 8, step : 854, G : 7.072232246398926\n",
      "EPOCH : 8, step : 855, D : 6.397902965545654\n",
      "EPOCH : 8, step : 856, G : 7.071691513061523\n",
      "EPOCH : 8, step : 857, D : 6.385356426239014\n",
      "EPOCH : 8, step : 858, G : 7.109584331512451\n",
      "EPOCH : 8, step : 859, D : 6.304523944854736\n",
      "EPOCH : 8, step : 860, G : 7.104043483734131\n",
      "EPOCH : 8, step : 861, D : 6.405430793762207\n",
      "EPOCH : 8, step : 862, G : 6.693262100219727\n",
      "EPOCH : 8, step : 863, D : 6.713984966278076\n",
      "EPOCH : 8, step : 864, G : 6.513049602508545\n",
      "EPOCH : 8, step : 865, D : 6.656358242034912\n",
      "EPOCH : 8, step : 866, G : 7.045389175415039\n",
      "EPOCH : 8, step : 867, D : 6.617068290710449\n",
      "EPOCH : 8, step : 868, G : 6.7164459228515625\n",
      "EPOCH : 8, step : 869, D : 6.484676837921143\n",
      "EPOCH : 8, step : 870, G : 7.234250545501709\n",
      "EPOCH : 8, step : 871, D : 6.422131061553955\n",
      "EPOCH : 8, step : 872, G : 7.048320293426514\n",
      "EPOCH : 8, step : 873, D : 6.279074668884277\n",
      "EPOCH : 8, step : 874, G : 7.163442611694336\n",
      "EPOCH : 8, step : 875, D : 6.344925880432129\n",
      "EPOCH : 8, step : 876, G : 7.020979881286621\n",
      "EPOCH : 8, step : 877, D : 6.43912410736084\n",
      "EPOCH : 8, step : 878, G : 7.210714340209961\n",
      "EPOCH : 8, step : 879, D : 6.421668529510498\n",
      "EPOCH : 8, step : 880, G : 6.912539958953857\n",
      "EPOCH : 9, step : 881, D : 6.376365661621094\n",
      "EPOCH : 9, step : 882, G : 7.124797821044922\n",
      "EPOCH : 9, step : 883, D : 6.228086948394775\n",
      "EPOCH : 9, step : 884, G : 7.170713901519775\n",
      "EPOCH : 9, step : 885, D : 6.280373573303223\n",
      "EPOCH : 9, step : 886, G : 7.271934986114502\n",
      "EPOCH : 9, step : 887, D : 6.265034198760986\n",
      "EPOCH : 9, step : 888, G : 7.1663994789123535\n",
      "EPOCH : 9, step : 889, D : 6.314499378204346\n",
      "EPOCH : 9, step : 890, G : 7.415109634399414\n",
      "EPOCH : 9, step : 891, D : 6.560807704925537\n",
      "EPOCH : 9, step : 892, G : 6.824878215789795\n",
      "EPOCH : 9, step : 893, D : 6.537757873535156\n",
      "EPOCH : 9, step : 894, G : 7.107358932495117\n",
      "EPOCH : 9, step : 895, D : 6.259266376495361\n",
      "EPOCH : 9, step : 896, G : 7.039425849914551\n",
      "EPOCH : 9, step : 897, D : 6.1464762687683105\n",
      "EPOCH : 9, step : 898, G : 7.012966156005859\n",
      "EPOCH : 9, step : 899, D : 6.151031970977783\n",
      "EPOCH : 9, step : 900, G : 6.956916809082031\n",
      "EPOCH : 9, step : 901, D : 6.18105936050415\n",
      "EPOCH : 9, step : 902, G : 6.986971378326416\n",
      "EPOCH : 9, step : 903, D : 6.115176200866699\n",
      "EPOCH : 9, step : 904, G : 7.0011749267578125\n",
      "EPOCH : 9, step : 905, D : 6.020423412322998\n",
      "EPOCH : 9, step : 906, G : 6.97168493270874\n",
      "EPOCH : 9, step : 907, D : 6.177971839904785\n",
      "EPOCH : 9, step : 908, G : 7.505029678344727\n",
      "EPOCH : 9, step : 909, D : 6.4080986976623535\n",
      "EPOCH : 9, step : 910, G : 6.725146770477295\n",
      "EPOCH : 9, step : 911, D : 6.872108459472656\n",
      "EPOCH : 9, step : 912, G : 6.9024505615234375\n",
      "EPOCH : 9, step : 913, D : 6.545063495635986\n",
      "EPOCH : 9, step : 914, G : 6.95028829574585\n",
      "EPOCH : 9, step : 915, D : 6.605741500854492\n",
      "EPOCH : 9, step : 916, G : 6.933737277984619\n",
      "EPOCH : 9, step : 917, D : 6.341532230377197\n",
      "EPOCH : 9, step : 918, G : 6.837319374084473\n",
      "EPOCH : 9, step : 919, D : 6.370870113372803\n",
      "EPOCH : 9, step : 920, G : 7.090125560760498\n",
      "EPOCH : 9, step : 921, D : 6.315679550170898\n",
      "EPOCH : 9, step : 922, G : 7.040891647338867\n",
      "EPOCH : 9, step : 923, D : 6.274693489074707\n",
      "EPOCH : 9, step : 924, G : 7.033069133758545\n",
      "EPOCH : 9, step : 925, D : 6.280537128448486\n",
      "EPOCH : 9, step : 926, G : 7.12518310546875\n",
      "EPOCH : 9, step : 927, D : 6.341716289520264\n",
      "EPOCH : 9, step : 928, G : 6.947338104248047\n",
      "EPOCH : 9, step : 929, D : 6.326169490814209\n",
      "EPOCH : 9, step : 930, G : 7.191179275512695\n",
      "EPOCH : 9, step : 931, D : 6.346408367156982\n",
      "EPOCH : 9, step : 932, G : 7.159169673919678\n",
      "EPOCH : 9, step : 933, D : 6.240385055541992\n",
      "EPOCH : 9, step : 934, G : 6.981353282928467\n",
      "EPOCH : 9, step : 935, D : 6.110820770263672\n",
      "EPOCH : 9, step : 936, G : 7.1850409507751465\n",
      "EPOCH : 9, step : 937, D : 6.253542900085449\n",
      "EPOCH : 9, step : 938, G : 6.5812668800354\n",
      "EPOCH : 9, step : 939, D : 6.88444185256958\n",
      "EPOCH : 9, step : 940, G : 6.897788047790527\n",
      "EPOCH : 9, step : 941, D : 6.317392826080322\n",
      "EPOCH : 9, step : 942, G : 7.360763072967529\n",
      "EPOCH : 9, step : 943, D : 6.483475208282471\n",
      "EPOCH : 9, step : 944, G : 6.890410900115967\n",
      "EPOCH : 9, step : 945, D : 6.378299713134766\n",
      "EPOCH : 9, step : 946, G : 6.802122116088867\n",
      "EPOCH : 9, step : 947, D : 6.532819747924805\n",
      "EPOCH : 9, step : 948, G : 7.045189380645752\n",
      "EPOCH : 9, step : 949, D : 6.610899925231934\n",
      "EPOCH : 9, step : 950, G : 6.65238094329834\n",
      "EPOCH : 9, step : 951, D : 6.381642818450928\n",
      "EPOCH : 9, step : 952, G : 7.139043807983398\n",
      "EPOCH : 9, step : 953, D : 6.3701019287109375\n",
      "EPOCH : 9, step : 954, G : 6.999130725860596\n",
      "EPOCH : 9, step : 955, D : 6.315334320068359\n",
      "EPOCH : 9, step : 956, G : 6.974165916442871\n",
      "EPOCH : 9, step : 957, D : 6.246310710906982\n",
      "EPOCH : 9, step : 958, G : 7.2542009353637695\n",
      "EPOCH : 9, step : 959, D : 6.265534400939941\n",
      "EPOCH : 9, step : 960, G : 6.892712116241455\n",
      "EPOCH : 9, step : 961, D : 6.3482441902160645\n",
      "EPOCH : 9, step : 962, G : 7.365518569946289\n",
      "EPOCH : 9, step : 963, D : 6.359420299530029\n",
      "EPOCH : 9, step : 964, G : 6.937735557556152\n",
      "EPOCH : 9, step : 965, D : 6.459704875946045\n",
      "EPOCH : 9, step : 966, G : 6.971738338470459\n",
      "EPOCH : 9, step : 967, D : 6.318110466003418\n",
      "EPOCH : 9, step : 968, G : 7.003530979156494\n",
      "EPOCH : 9, step : 969, D : 6.423766136169434\n",
      "EPOCH : 9, step : 970, G : 7.050899982452393\n",
      "EPOCH : 9, step : 971, D : 6.207093715667725\n",
      "EPOCH : 9, step : 972, G : 6.905678749084473\n",
      "EPOCH : 9, step : 973, D : 6.206674098968506\n",
      "EPOCH : 9, step : 974, G : 6.950201988220215\n",
      "EPOCH : 9, step : 975, D : 6.193439960479736\n",
      "EPOCH : 9, step : 976, G : 6.942195892333984\n",
      "EPOCH : 9, step : 977, D : 6.179187297821045\n",
      "EPOCH : 9, step : 978, G : 7.129928112030029\n",
      "EPOCH : 9, step : 979, D : 6.4830002784729\n",
      "EPOCH : 9, step : 980, G : 6.55797004699707\n",
      "EPOCH : 9, step : 981, D : 6.634768962860107\n",
      "EPOCH : 9, step : 982, G : 6.890460968017578\n",
      "EPOCH : 9, step : 983, D : 6.29330587387085\n",
      "EPOCH : 9, step : 984, G : 7.013823509216309\n",
      "EPOCH : 9, step : 985, D : 6.267834186553955\n",
      "EPOCH : 9, step : 986, G : 6.864656925201416\n",
      "EPOCH : 9, step : 987, D : 6.348113059997559\n",
      "EPOCH : 9, step : 988, G : 7.028928756713867\n",
      "EPOCH : 9, step : 989, D : 6.304187774658203\n",
      "EPOCH : 9, step : 990, G : 6.851188659667969\n",
      "EPOCH : 10, step : 991, D : 6.218016624450684\n",
      "EPOCH : 10, step : 992, G : 6.890472888946533\n",
      "EPOCH : 10, step : 993, D : 6.209031581878662\n",
      "EPOCH : 10, step : 994, G : 7.243624687194824\n",
      "EPOCH : 10, step : 995, D : 6.197094917297363\n",
      "EPOCH : 10, step : 996, G : 6.720619201660156\n",
      "EPOCH : 10, step : 997, D : 6.298840522766113\n",
      "EPOCH : 10, step : 998, G : 7.104823589324951\n",
      "EPOCH : 10, step : 999, D : 6.198910236358643\n",
      "EPOCH : 10, step : 1000, G : 6.7154998779296875\n",
      "EPOCH : 10, step : 1001, D : 6.237333297729492\n",
      "EPOCH : 10, step : 1002, G : 7.1329803466796875\n",
      "EPOCH : 10, step : 1003, D : 6.128965854644775\n",
      "EPOCH : 10, step : 1004, G : 6.95611572265625\n",
      "EPOCH : 10, step : 1005, D : 6.05131196975708\n",
      "EPOCH : 10, step : 1006, G : 6.957563877105713\n",
      "EPOCH : 10, step : 1007, D : 6.234649181365967\n",
      "EPOCH : 10, step : 1008, G : 7.327563285827637\n",
      "EPOCH : 10, step : 1009, D : 6.363504409790039\n",
      "EPOCH : 10, step : 1010, G : 6.721643924713135\n",
      "EPOCH : 10, step : 1011, D : 6.540716648101807\n",
      "EPOCH : 10, step : 1012, G : 7.094972610473633\n",
      "EPOCH : 10, step : 1013, D : 6.472756385803223\n",
      "EPOCH : 10, step : 1014, G : 6.808465003967285\n",
      "EPOCH : 10, step : 1015, D : 6.260435104370117\n",
      "EPOCH : 10, step : 1016, G : 6.917627811431885\n",
      "EPOCH : 10, step : 1017, D : 6.423472881317139\n",
      "EPOCH : 10, step : 1018, G : 6.897113800048828\n",
      "EPOCH : 10, step : 1019, D : 6.115969657897949\n",
      "EPOCH : 10, step : 1020, G : 7.02232551574707\n",
      "EPOCH : 10, step : 1021, D : 6.384321689605713\n",
      "EPOCH : 10, step : 1022, G : 7.015963554382324\n",
      "EPOCH : 10, step : 1023, D : 6.38590145111084\n",
      "EPOCH : 10, step : 1024, G : 7.004368305206299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 10, step : 1025, D : 6.152266502380371\n",
      "EPOCH : 10, step : 1026, G : 7.216885566711426\n",
      "EPOCH : 10, step : 1027, D : 6.1125006675720215\n",
      "EPOCH : 10, step : 1028, G : 7.027321815490723\n",
      "EPOCH : 10, step : 1029, D : 6.064948558807373\n",
      "EPOCH : 10, step : 1030, G : 7.001389503479004\n",
      "EPOCH : 10, step : 1031, D : 5.868066310882568\n",
      "EPOCH : 10, step : 1032, G : 7.198128700256348\n",
      "EPOCH : 10, step : 1033, D : 6.150226593017578\n",
      "EPOCH : 10, step : 1034, G : 7.49027156829834\n",
      "EPOCH : 10, step : 1035, D : 6.661647319793701\n",
      "EPOCH : 10, step : 1036, G : 6.733563423156738\n",
      "EPOCH : 10, step : 1037, D : 6.45571231842041\n",
      "EPOCH : 10, step : 1038, G : 6.7764129638671875\n",
      "EPOCH : 10, step : 1039, D : 6.177024841308594\n",
      "EPOCH : 10, step : 1040, G : 6.920872211456299\n",
      "EPOCH : 10, step : 1041, D : 6.241705894470215\n",
      "EPOCH : 10, step : 1042, G : 7.134250164031982\n",
      "EPOCH : 10, step : 1043, D : 6.1908650398254395\n",
      "EPOCH : 10, step : 1044, G : 6.944128513336182\n",
      "EPOCH : 10, step : 1045, D : 6.12034797668457\n",
      "EPOCH : 10, step : 1046, G : 7.0874857902526855\n",
      "EPOCH : 10, step : 1047, D : 6.133032321929932\n",
      "EPOCH : 10, step : 1048, G : 6.878021240234375\n",
      "EPOCH : 10, step : 1049, D : 6.254635334014893\n",
      "EPOCH : 10, step : 1050, G : 7.407548904418945\n",
      "EPOCH : 10, step : 1051, D : 6.153568267822266\n",
      "EPOCH : 10, step : 1052, G : 6.884697437286377\n",
      "EPOCH : 10, step : 1053, D : 6.421535491943359\n",
      "EPOCH : 10, step : 1054, G : 7.057644844055176\n",
      "EPOCH : 10, step : 1055, D : 6.503389358520508\n",
      "EPOCH : 10, step : 1056, G : 6.71794319152832\n",
      "EPOCH : 10, step : 1057, D : 6.21367883682251\n",
      "EPOCH : 10, step : 1058, G : 7.0841240882873535\n",
      "EPOCH : 10, step : 1059, D : 6.195871353149414\n",
      "EPOCH : 10, step : 1060, G : 7.339620113372803\n",
      "EPOCH : 10, step : 1061, D : 6.149572372436523\n",
      "EPOCH : 10, step : 1062, G : 6.8476881980896\n",
      "EPOCH : 10, step : 1063, D : 6.319164752960205\n",
      "EPOCH : 10, step : 1064, G : 6.975525856018066\n",
      "EPOCH : 10, step : 1065, D : 6.205346584320068\n",
      "EPOCH : 10, step : 1066, G : 6.925287246704102\n",
      "EPOCH : 10, step : 1067, D : 6.233218669891357\n",
      "EPOCH : 10, step : 1068, G : 7.1580424308776855\n",
      "EPOCH : 10, step : 1069, D : 6.684584140777588\n",
      "EPOCH : 10, step : 1070, G : 6.877224445343018\n",
      "EPOCH : 10, step : 1071, D : 6.0570268630981445\n",
      "EPOCH : 10, step : 1072, G : 6.623623371124268\n",
      "EPOCH : 10, step : 1073, D : 6.305124759674072\n",
      "EPOCH : 10, step : 1074, G : 6.842848777770996\n",
      "EPOCH : 10, step : 1075, D : 6.254181385040283\n",
      "EPOCH : 10, step : 1076, G : 6.881644248962402\n",
      "EPOCH : 10, step : 1077, D : 6.114917278289795\n",
      "EPOCH : 10, step : 1078, G : 6.818513870239258\n",
      "EPOCH : 10, step : 1079, D : 6.136487007141113\n",
      "EPOCH : 10, step : 1080, G : 7.243926525115967\n",
      "EPOCH : 10, step : 1081, D : 6.241545677185059\n",
      "EPOCH : 10, step : 1082, G : 6.890299320220947\n",
      "EPOCH : 10, step : 1083, D : 6.368300437927246\n",
      "EPOCH : 10, step : 1084, G : 7.24907922744751\n",
      "EPOCH : 10, step : 1085, D : 6.4166741371154785\n",
      "EPOCH : 10, step : 1086, G : 6.9813408851623535\n",
      "EPOCH : 10, step : 1087, D : 6.101698398590088\n",
      "EPOCH : 10, step : 1088, G : 6.821849822998047\n",
      "EPOCH : 10, step : 1089, D : 6.130383491516113\n",
      "EPOCH : 10, step : 1090, G : 7.158271312713623\n",
      "EPOCH : 10, step : 1091, D : 6.045769214630127\n",
      "EPOCH : 10, step : 1092, G : 7.080768585205078\n",
      "EPOCH : 10, step : 1093, D : 6.019252300262451\n",
      "EPOCH : 10, step : 1094, G : 7.300591468811035\n",
      "EPOCH : 10, step : 1095, D : 6.308193683624268\n",
      "EPOCH : 10, step : 1096, G : 6.726528167724609\n",
      "EPOCH : 10, step : 1097, D : 6.608903408050537\n",
      "EPOCH : 10, step : 1098, G : 6.720902442932129\n",
      "EPOCH : 10, step : 1099, D : 6.546561241149902\n",
      "EPOCH : 10, step : 1100, G : 6.966884613037109\n",
      "EPOCH : 11, step : 1101, D : 6.468967914581299\n",
      "EPOCH : 11, step : 1102, G : 6.93892240524292\n",
      "EPOCH : 11, step : 1103, D : 6.098160743713379\n",
      "EPOCH : 11, step : 1104, G : 6.801938533782959\n",
      "EPOCH : 11, step : 1105, D : 6.128024101257324\n",
      "EPOCH : 11, step : 1106, G : 7.163509845733643\n",
      "EPOCH : 11, step : 1107, D : 6.167490005493164\n",
      "EPOCH : 11, step : 1108, G : 6.7664713859558105\n",
      "EPOCH : 11, step : 1109, D : 6.3412861824035645\n",
      "EPOCH : 11, step : 1110, G : 7.284724712371826\n",
      "EPOCH : 11, step : 1111, D : 6.298645496368408\n",
      "EPOCH : 11, step : 1112, G : 6.875229358673096\n",
      "EPOCH : 11, step : 1113, D : 6.10505485534668\n",
      "EPOCH : 11, step : 1114, G : 6.78856086730957\n",
      "EPOCH : 11, step : 1115, D : 6.143212795257568\n",
      "EPOCH : 11, step : 1116, G : 6.987727642059326\n",
      "EPOCH : 11, step : 1117, D : 6.060034275054932\n",
      "EPOCH : 11, step : 1118, G : 7.001012325286865\n",
      "EPOCH : 11, step : 1119, D : 6.099000453948975\n",
      "EPOCH : 11, step : 1120, G : 6.778461933135986\n",
      "EPOCH : 11, step : 1121, D : 6.070255279541016\n",
      "EPOCH : 11, step : 1122, G : 7.204566478729248\n",
      "EPOCH : 11, step : 1123, D : 6.152409076690674\n",
      "EPOCH : 11, step : 1124, G : 6.338826656341553\n",
      "EPOCH : 11, step : 1125, D : 6.462259292602539\n",
      "EPOCH : 11, step : 1126, G : 6.91925573348999\n",
      "EPOCH : 11, step : 1127, D : 6.289754390716553\n",
      "EPOCH : 11, step : 1128, G : 6.90746545791626\n",
      "EPOCH : 11, step : 1129, D : 6.1954026222229\n",
      "EPOCH : 11, step : 1130, G : 6.698105335235596\n",
      "EPOCH : 11, step : 1131, D : 6.477793216705322\n",
      "EPOCH : 11, step : 1132, G : 7.0428466796875\n",
      "EPOCH : 11, step : 1133, D : 6.361473083496094\n",
      "EPOCH : 11, step : 1134, G : 6.538665294647217\n",
      "EPOCH : 11, step : 1135, D : 6.440802574157715\n",
      "EPOCH : 11, step : 1136, G : 6.874666213989258\n",
      "EPOCH : 11, step : 1137, D : 6.140512943267822\n",
      "EPOCH : 11, step : 1138, G : 6.895533561706543\n",
      "EPOCH : 11, step : 1139, D : 6.069008827209473\n",
      "EPOCH : 11, step : 1140, G : 6.916136264801025\n",
      "EPOCH : 11, step : 1141, D : 6.161214828491211\n",
      "EPOCH : 11, step : 1142, G : 7.081036567687988\n",
      "EPOCH : 11, step : 1143, D : 6.056124210357666\n",
      "EPOCH : 11, step : 1144, G : 6.84354305267334\n",
      "EPOCH : 11, step : 1145, D : 6.151261329650879\n",
      "EPOCH : 11, step : 1146, G : 6.905306816101074\n",
      "EPOCH : 11, step : 1147, D : 6.248625755310059\n",
      "EPOCH : 11, step : 1148, G : 6.784115791320801\n",
      "EPOCH : 11, step : 1149, D : 6.347928047180176\n",
      "EPOCH : 11, step : 1150, G : 6.867326736450195\n",
      "EPOCH : 11, step : 1151, D : 6.095737934112549\n",
      "EPOCH : 11, step : 1152, G : 7.161304950714111\n",
      "EPOCH : 11, step : 1153, D : 6.089549541473389\n",
      "EPOCH : 11, step : 1154, G : 6.975114822387695\n",
      "EPOCH : 11, step : 1155, D : 6.141793251037598\n",
      "EPOCH : 11, step : 1156, G : 7.240649223327637\n",
      "EPOCH : 11, step : 1157, D : 6.464160442352295\n",
      "EPOCH : 11, step : 1158, G : 6.600071430206299\n",
      "EPOCH : 11, step : 1159, D : 6.350445747375488\n",
      "EPOCH : 11, step : 1160, G : 6.975627422332764\n",
      "EPOCH : 11, step : 1161, D : 6.118453502655029\n",
      "EPOCH : 11, step : 1162, G : 6.885971546173096\n",
      "EPOCH : 11, step : 1163, D : 6.167047023773193\n",
      "EPOCH : 11, step : 1164, G : 6.881962776184082\n",
      "EPOCH : 11, step : 1165, D : 5.970520496368408\n",
      "EPOCH : 11, step : 1166, G : 7.115661144256592\n",
      "EPOCH : 11, step : 1167, D : 6.081923007965088\n",
      "EPOCH : 11, step : 1168, G : 6.966409683227539\n",
      "EPOCH : 11, step : 1169, D : 6.062726020812988\n",
      "EPOCH : 11, step : 1170, G : 6.900630474090576\n",
      "EPOCH : 11, step : 1171, D : 5.900112152099609\n",
      "EPOCH : 11, step : 1172, G : 7.251693248748779\n",
      "EPOCH : 11, step : 1173, D : 6.190616130828857\n",
      "EPOCH : 11, step : 1174, G : 6.396511077880859\n",
      "EPOCH : 11, step : 1175, D : 6.50391960144043\n",
      "EPOCH : 11, step : 1176, G : 6.832029342651367\n",
      "EPOCH : 11, step : 1177, D : 6.070837497711182\n",
      "EPOCH : 11, step : 1178, G : 6.978494644165039\n",
      "EPOCH : 11, step : 1179, D : 6.0931267738342285\n",
      "EPOCH : 11, step : 1180, G : 6.4586181640625\n",
      "EPOCH : 11, step : 1181, D : 6.43964958190918\n",
      "EPOCH : 11, step : 1182, G : 7.075667858123779\n",
      "EPOCH : 11, step : 1183, D : 6.081034183502197\n",
      "EPOCH : 11, step : 1184, G : 7.079670429229736\n",
      "EPOCH : 11, step : 1185, D : 6.036571979522705\n",
      "EPOCH : 11, step : 1186, G : 6.543092727661133\n",
      "EPOCH : 11, step : 1187, D : 5.947532653808594\n",
      "EPOCH : 11, step : 1188, G : 7.0703840255737305\n",
      "EPOCH : 11, step : 1189, D : 5.983602523803711\n",
      "EPOCH : 11, step : 1190, G : 7.000695705413818\n",
      "EPOCH : 11, step : 1191, D : 6.208343029022217\n",
      "EPOCH : 11, step : 1192, G : 7.264204978942871\n",
      "EPOCH : 11, step : 1193, D : 6.074900150299072\n",
      "EPOCH : 11, step : 1194, G : 6.991293907165527\n",
      "EPOCH : 11, step : 1195, D : 6.11356782913208\n",
      "EPOCH : 11, step : 1196, G : 7.0763840675354\n",
      "EPOCH : 11, step : 1197, D : 5.8436174392700195\n",
      "EPOCH : 11, step : 1198, G : 7.18852424621582\n",
      "EPOCH : 11, step : 1199, D : 5.915329456329346\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 11, step : 1200, G : 6.571808815002441\n",
      "EPOCH : 11, step : 1201, D : 6.6071457862854\n",
      "EPOCH : 11, step : 1202, G : 7.169093608856201\n",
      "EPOCH : 11, step : 1203, D : 6.567954063415527\n",
      "EPOCH : 11, step : 1204, G : 6.556551933288574\n",
      "EPOCH : 11, step : 1205, D : 6.401123046875\n",
      "EPOCH : 11, step : 1206, G : 6.726420879364014\n",
      "EPOCH : 11, step : 1207, D : 6.201216697692871\n",
      "EPOCH : 11, step : 1208, G : 6.8428144454956055\n",
      "EPOCH : 11, step : 1209, D : 6.041626453399658\n",
      "EPOCH : 11, step : 1210, G : 6.564837455749512\n",
      "EPOCH : 12, step : 1211, D : 6.212036609649658\n",
      "EPOCH : 12, step : 1212, G : 7.115494251251221\n",
      "EPOCH : 12, step : 1213, D : 6.083163261413574\n",
      "EPOCH : 12, step : 1214, G : 7.176898002624512\n",
      "EPOCH : 12, step : 1215, D : 5.940834999084473\n",
      "EPOCH : 12, step : 1216, G : 6.817367076873779\n",
      "EPOCH : 12, step : 1217, D : 6.130165100097656\n",
      "EPOCH : 12, step : 1218, G : 7.156674385070801\n",
      "EPOCH : 12, step : 1219, D : 5.963457107543945\n",
      "EPOCH : 12, step : 1220, G : 7.013247966766357\n",
      "EPOCH : 12, step : 1221, D : 5.939055442810059\n",
      "EPOCH : 12, step : 1222, G : 7.038912773132324\n",
      "EPOCH : 12, step : 1223, D : 5.809294700622559\n",
      "EPOCH : 12, step : 1224, G : 7.035500526428223\n",
      "EPOCH : 12, step : 1225, D : 5.857090950012207\n",
      "EPOCH : 12, step : 1226, G : 7.003719329833984\n",
      "EPOCH : 12, step : 1227, D : 5.912686824798584\n",
      "EPOCH : 12, step : 1228, G : 7.162820339202881\n",
      "EPOCH : 12, step : 1229, D : 5.824491024017334\n",
      "EPOCH : 12, step : 1230, G : 7.084860324859619\n",
      "EPOCH : 12, step : 1231, D : 6.095945835113525\n",
      "EPOCH : 12, step : 1232, G : 6.646928787231445\n",
      "EPOCH : 12, step : 1233, D : 6.465542316436768\n",
      "EPOCH : 12, step : 1234, G : 6.729210376739502\n",
      "EPOCH : 12, step : 1235, D : 5.920907497406006\n",
      "EPOCH : 12, step : 1236, G : 7.249838829040527\n",
      "EPOCH : 12, step : 1237, D : 6.262303829193115\n",
      "EPOCH : 12, step : 1238, G : 6.9875102043151855\n",
      "EPOCH : 12, step : 1239, D : 6.300756931304932\n",
      "EPOCH : 12, step : 1240, G : 6.457042694091797\n",
      "EPOCH : 12, step : 1241, D : 6.538886070251465\n",
      "EPOCH : 12, step : 1242, G : 6.806583404541016\n",
      "EPOCH : 12, step : 1243, D : 6.100665092468262\n",
      "EPOCH : 12, step : 1244, G : 6.686915874481201\n",
      "EPOCH : 12, step : 1245, D : 6.2192769050598145\n",
      "EPOCH : 12, step : 1246, G : 6.653670787811279\n",
      "EPOCH : 12, step : 1247, D : 6.16754150390625\n",
      "EPOCH : 12, step : 1248, G : 7.172039031982422\n",
      "EPOCH : 12, step : 1249, D : 6.072607040405273\n",
      "EPOCH : 12, step : 1250, G : 6.611007213592529\n",
      "EPOCH : 12, step : 1251, D : 6.085339546203613\n",
      "EPOCH : 12, step : 1252, G : 7.192759037017822\n",
      "EPOCH : 12, step : 1253, D : 6.023869037628174\n",
      "EPOCH : 12, step : 1254, G : 6.827068328857422\n",
      "EPOCH : 12, step : 1255, D : 5.8923115730285645\n",
      "EPOCH : 12, step : 1256, G : 6.981613636016846\n",
      "EPOCH : 12, step : 1257, D : 5.877997875213623\n",
      "EPOCH : 12, step : 1258, G : 6.504377841949463\n",
      "EPOCH : 12, step : 1259, D : 6.160046100616455\n",
      "EPOCH : 12, step : 1260, G : 6.868602275848389\n",
      "EPOCH : 12, step : 1261, D : 6.200035095214844\n",
      "EPOCH : 12, step : 1262, G : 6.843867778778076\n",
      "EPOCH : 12, step : 1263, D : 6.0572943687438965\n",
      "EPOCH : 12, step : 1264, G : 7.123325347900391\n",
      "EPOCH : 12, step : 1265, D : 6.095961093902588\n",
      "EPOCH : 12, step : 1266, G : 6.942525386810303\n",
      "EPOCH : 12, step : 1267, D : 6.106984615325928\n",
      "EPOCH : 12, step : 1268, G : 6.902658462524414\n",
      "EPOCH : 12, step : 1269, D : 6.100095748901367\n",
      "EPOCH : 12, step : 1270, G : 7.070562839508057\n",
      "EPOCH : 12, step : 1271, D : 6.2457075119018555\n",
      "EPOCH : 12, step : 1272, G : 6.5212788581848145\n",
      "EPOCH : 12, step : 1273, D : 6.126936912536621\n",
      "EPOCH : 12, step : 1274, G : 7.04263973236084\n",
      "EPOCH : 12, step : 1275, D : 6.034095764160156\n",
      "EPOCH : 12, step : 1276, G : 7.037868022918701\n",
      "EPOCH : 12, step : 1277, D : 6.0902934074401855\n",
      "EPOCH : 12, step : 1278, G : 6.7955522537231445\n",
      "EPOCH : 12, step : 1279, D : 6.070930004119873\n",
      "EPOCH : 12, step : 1280, G : 7.249653339385986\n",
      "EPOCH : 12, step : 1281, D : 6.186636447906494\n",
      "EPOCH : 12, step : 1282, G : 6.665162086486816\n",
      "EPOCH : 12, step : 1283, D : 6.122628688812256\n",
      "EPOCH : 12, step : 1284, G : 7.059241771697998\n",
      "EPOCH : 12, step : 1285, D : 5.839323043823242\n",
      "EPOCH : 12, step : 1286, G : 7.231459617614746\n",
      "EPOCH : 12, step : 1287, D : 5.964337348937988\n",
      "EPOCH : 12, step : 1288, G : 6.63660192489624\n",
      "EPOCH : 12, step : 1289, D : 5.947790622711182\n",
      "EPOCH : 12, step : 1290, G : 6.9677886962890625\n",
      "EPOCH : 12, step : 1291, D : 6.022799491882324\n",
      "EPOCH : 12, step : 1292, G : 6.97492790222168\n",
      "EPOCH : 12, step : 1293, D : 5.874238014221191\n",
      "EPOCH : 12, step : 1294, G : 7.009115219116211\n",
      "EPOCH : 12, step : 1295, D : 5.9187846183776855\n",
      "EPOCH : 12, step : 1296, G : 6.975876331329346\n",
      "EPOCH : 12, step : 1297, D : 5.953207969665527\n",
      "EPOCH : 12, step : 1298, G : 6.889630317687988\n",
      "EPOCH : 12, step : 1299, D : 5.980160713195801\n",
      "EPOCH : 12, step : 1300, G : 7.509692192077637\n",
      "EPOCH : 12, step : 1301, D : 6.569085597991943\n",
      "EPOCH : 12, step : 1302, G : 6.670164585113525\n",
      "EPOCH : 12, step : 1303, D : 6.044338226318359\n",
      "EPOCH : 12, step : 1304, G : 6.79968786239624\n",
      "EPOCH : 12, step : 1305, D : 6.139585494995117\n",
      "EPOCH : 12, step : 1306, G : 6.979659080505371\n",
      "EPOCH : 12, step : 1307, D : 5.942378044128418\n",
      "EPOCH : 12, step : 1308, G : 6.712260723114014\n",
      "EPOCH : 12, step : 1309, D : 5.994663715362549\n",
      "EPOCH : 12, step : 1310, G : 6.978113651275635\n",
      "EPOCH : 12, step : 1311, D : 5.921682357788086\n",
      "EPOCH : 12, step : 1312, G : 6.730252742767334\n",
      "EPOCH : 12, step : 1313, D : 6.037805557250977\n",
      "EPOCH : 12, step : 1314, G : 6.961353778839111\n",
      "EPOCH : 12, step : 1315, D : 5.938716888427734\n",
      "EPOCH : 12, step : 1316, G : 6.451729774475098\n",
      "EPOCH : 12, step : 1317, D : 6.016622066497803\n",
      "EPOCH : 12, step : 1318, G : 6.894350051879883\n",
      "EPOCH : 12, step : 1319, D : 5.967022895812988\n",
      "EPOCH : 12, step : 1320, G : 6.731733798980713\n",
      "EPOCH : 13, step : 1321, D : 6.0075273513793945\n",
      "EPOCH : 13, step : 1322, G : 7.050955772399902\n",
      "EPOCH : 13, step : 1323, D : 6.040082931518555\n",
      "EPOCH : 13, step : 1324, G : 6.528534889221191\n",
      "EPOCH : 13, step : 1325, D : 6.230208873748779\n",
      "EPOCH : 13, step : 1326, G : 7.025125980377197\n",
      "EPOCH : 13, step : 1327, D : 5.991591930389404\n",
      "EPOCH : 13, step : 1328, G : 6.943799018859863\n",
      "EPOCH : 13, step : 1329, D : 5.932436943054199\n",
      "EPOCH : 13, step : 1330, G : 6.793994426727295\n",
      "EPOCH : 13, step : 1331, D : 5.939600467681885\n",
      "EPOCH : 13, step : 1332, G : 7.0071187019348145\n",
      "EPOCH : 13, step : 1333, D : 5.873919486999512\n",
      "EPOCH : 13, step : 1334, G : 6.568493366241455\n",
      "EPOCH : 13, step : 1335, D : 5.899514675140381\n",
      "EPOCH : 13, step : 1336, G : 7.2557573318481445\n",
      "EPOCH : 13, step : 1337, D : 6.088250160217285\n",
      "EPOCH : 13, step : 1338, G : 6.71449089050293\n",
      "EPOCH : 13, step : 1339, D : 6.340626239776611\n",
      "EPOCH : 13, step : 1340, G : 6.802989959716797\n",
      "EPOCH : 13, step : 1341, D : 5.9523515701293945\n",
      "EPOCH : 13, step : 1342, G : 6.813076972961426\n",
      "EPOCH : 13, step : 1343, D : 5.997786998748779\n",
      "EPOCH : 13, step : 1344, G : 6.624877452850342\n",
      "EPOCH : 13, step : 1345, D : 5.833592891693115\n",
      "EPOCH : 13, step : 1346, G : 6.871715068817139\n",
      "EPOCH : 13, step : 1347, D : 6.144922256469727\n",
      "EPOCH : 13, step : 1348, G : 6.91158390045166\n",
      "EPOCH : 13, step : 1349, D : 5.940121173858643\n",
      "EPOCH : 13, step : 1350, G : 6.872476577758789\n",
      "EPOCH : 13, step : 1351, D : 5.90317440032959\n",
      "EPOCH : 13, step : 1352, G : 6.7195329666137695\n",
      "EPOCH : 13, step : 1353, D : 6.094890117645264\n",
      "EPOCH : 13, step : 1354, G : 7.219147205352783\n",
      "EPOCH : 13, step : 1355, D : 6.483874320983887\n",
      "EPOCH : 13, step : 1356, G : 6.768200874328613\n",
      "EPOCH : 13, step : 1357, D : 6.113060474395752\n",
      "EPOCH : 13, step : 1358, G : 6.534579753875732\n",
      "EPOCH : 13, step : 1359, D : 6.041320323944092\n",
      "EPOCH : 13, step : 1360, G : 6.779195785522461\n",
      "EPOCH : 13, step : 1361, D : 5.988607883453369\n",
      "EPOCH : 13, step : 1362, G : 6.58987283706665\n",
      "EPOCH : 13, step : 1363, D : 5.873630523681641\n",
      "EPOCH : 13, step : 1364, G : 6.9657440185546875\n",
      "EPOCH : 13, step : 1365, D : 5.828868865966797\n",
      "EPOCH : 13, step : 1366, G : 6.569705963134766\n",
      "EPOCH : 13, step : 1367, D : 6.005926609039307\n",
      "EPOCH : 13, step : 1368, G : 6.798098564147949\n",
      "EPOCH : 13, step : 1369, D : 5.939391613006592\n",
      "EPOCH : 13, step : 1370, G : 6.707118988037109\n",
      "EPOCH : 13, step : 1371, D : 5.875678062438965\n",
      "EPOCH : 13, step : 1372, G : 6.72022008895874\n",
      "EPOCH : 13, step : 1373, D : 5.823680877685547\n",
      "EPOCH : 13, step : 1374, G : 6.518432140350342\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 13, step : 1375, D : 5.87406063079834\n",
      "EPOCH : 13, step : 1376, G : 7.163100242614746\n",
      "EPOCH : 13, step : 1377, D : 5.8632659912109375\n",
      "EPOCH : 13, step : 1378, G : 6.59572696685791\n",
      "EPOCH : 13, step : 1379, D : 6.078794002532959\n",
      "EPOCH : 13, step : 1380, G : 7.13106632232666\n",
      "EPOCH : 13, step : 1381, D : 5.974859714508057\n",
      "EPOCH : 13, step : 1382, G : 6.669900417327881\n",
      "EPOCH : 13, step : 1383, D : 5.763886451721191\n",
      "EPOCH : 13, step : 1384, G : 6.8882317543029785\n",
      "EPOCH : 13, step : 1385, D : 5.918089389801025\n",
      "EPOCH : 13, step : 1386, G : 6.926290988922119\n",
      "EPOCH : 13, step : 1387, D : 5.883264064788818\n",
      "EPOCH : 13, step : 1388, G : 6.954230785369873\n",
      "EPOCH : 13, step : 1389, D : 5.874432563781738\n",
      "EPOCH : 13, step : 1390, G : 7.001430034637451\n",
      "EPOCH : 13, step : 1391, D : 5.852739334106445\n",
      "EPOCH : 13, step : 1392, G : 7.098095417022705\n",
      "EPOCH : 13, step : 1393, D : 5.946601867675781\n",
      "EPOCH : 13, step : 1394, G : 7.021731853485107\n",
      "EPOCH : 13, step : 1395, D : 5.792816638946533\n",
      "EPOCH : 13, step : 1396, G : 7.05879545211792\n",
      "EPOCH : 13, step : 1397, D : 5.6115312576293945\n",
      "EPOCH : 13, step : 1398, G : 7.030386447906494\n",
      "EPOCH : 13, step : 1399, D : 5.730579376220703\n",
      "EPOCH : 13, step : 1400, G : 6.515474319458008\n",
      "EPOCH : 13, step : 1401, D : 6.385915756225586\n",
      "EPOCH : 13, step : 1402, G : 6.9301605224609375\n",
      "EPOCH : 13, step : 1403, D : 6.1887359619140625\n",
      "EPOCH : 13, step : 1404, G : 6.269224643707275\n",
      "EPOCH : 13, step : 1405, D : 6.224691390991211\n",
      "EPOCH : 13, step : 1406, G : 6.744698524475098\n",
      "EPOCH : 13, step : 1407, D : 6.24416971206665\n",
      "EPOCH : 13, step : 1408, G : 6.8510918617248535\n",
      "EPOCH : 13, step : 1409, D : 6.070932388305664\n",
      "EPOCH : 13, step : 1410, G : 6.9761152267456055\n",
      "EPOCH : 13, step : 1411, D : 6.090066432952881\n",
      "EPOCH : 13, step : 1412, G : 6.743756294250488\n",
      "EPOCH : 13, step : 1413, D : 5.937101364135742\n",
      "EPOCH : 13, step : 1414, G : 6.951564788818359\n",
      "EPOCH : 13, step : 1415, D : 5.706276893615723\n",
      "EPOCH : 13, step : 1416, G : 6.863761901855469\n",
      "EPOCH : 13, step : 1417, D : 5.848128318786621\n",
      "EPOCH : 13, step : 1418, G : 6.749760627746582\n",
      "EPOCH : 13, step : 1419, D : 5.719956398010254\n",
      "EPOCH : 13, step : 1420, G : 6.910489082336426\n",
      "EPOCH : 13, step : 1421, D : 5.800384521484375\n",
      "EPOCH : 13, step : 1422, G : 6.474175453186035\n",
      "EPOCH : 13, step : 1423, D : 6.173836708068848\n",
      "EPOCH : 13, step : 1424, G : 7.427759170532227\n",
      "EPOCH : 13, step : 1425, D : 6.15938663482666\n",
      "EPOCH : 13, step : 1426, G : 6.322447776794434\n",
      "EPOCH : 13, step : 1427, D : 6.3073649406433105\n",
      "EPOCH : 13, step : 1428, G : 6.706146717071533\n",
      "EPOCH : 13, step : 1429, D : 5.843207836151123\n",
      "EPOCH : 13, step : 1430, G : 6.864016056060791\n",
      "EPOCH : 14, step : 1431, D : 5.8282270431518555\n",
      "EPOCH : 14, step : 1432, G : 6.697702884674072\n",
      "EPOCH : 14, step : 1433, D : 6.166783809661865\n",
      "EPOCH : 14, step : 1434, G : 6.868284225463867\n",
      "EPOCH : 14, step : 1435, D : 5.888631820678711\n",
      "EPOCH : 14, step : 1436, G : 6.7852702140808105\n",
      "EPOCH : 14, step : 1437, D : 5.975541114807129\n",
      "EPOCH : 14, step : 1438, G : 6.7266340255737305\n",
      "EPOCH : 14, step : 1439, D : 6.030330181121826\n",
      "EPOCH : 14, step : 1440, G : 6.923678398132324\n",
      "EPOCH : 14, step : 1441, D : 5.98936128616333\n",
      "EPOCH : 14, step : 1442, G : 6.726865291595459\n",
      "EPOCH : 14, step : 1443, D : 5.813716888427734\n",
      "EPOCH : 14, step : 1444, G : 7.313616752624512\n",
      "EPOCH : 14, step : 1445, D : 5.7439117431640625\n",
      "EPOCH : 14, step : 1446, G : 7.241067409515381\n",
      "EPOCH : 14, step : 1447, D : 5.709388732910156\n",
      "EPOCH : 14, step : 1448, G : 6.939670562744141\n",
      "EPOCH : 14, step : 1449, D : 6.056381702423096\n",
      "EPOCH : 14, step : 1450, G : 7.438992500305176\n",
      "EPOCH : 14, step : 1451, D : 6.018696308135986\n",
      "EPOCH : 14, step : 1452, G : 6.4415764808654785\n",
      "EPOCH : 14, step : 1453, D : 6.215500354766846\n",
      "EPOCH : 14, step : 1454, G : 7.061769485473633\n",
      "EPOCH : 14, step : 1455, D : 5.767096996307373\n",
      "EPOCH : 14, step : 1456, G : 6.989422798156738\n",
      "EPOCH : 14, step : 1457, D : 5.858209133148193\n",
      "EPOCH : 14, step : 1458, G : 6.904468536376953\n",
      "EPOCH : 14, step : 1459, D : 5.576666355133057\n",
      "EPOCH : 14, step : 1460, G : 6.906477928161621\n",
      "EPOCH : 14, step : 1461, D : 5.723331928253174\n",
      "EPOCH : 14, step : 1462, G : 7.149576663970947\n",
      "EPOCH : 14, step : 1463, D : 5.716029644012451\n",
      "EPOCH : 14, step : 1464, G : 6.544638156890869\n",
      "EPOCH : 14, step : 1465, D : 6.205341339111328\n",
      "EPOCH : 14, step : 1466, G : 6.956808090209961\n",
      "EPOCH : 14, step : 1467, D : 5.937694072723389\n",
      "EPOCH : 14, step : 1468, G : 6.536091327667236\n",
      "EPOCH : 14, step : 1469, D : 6.130671977996826\n",
      "EPOCH : 14, step : 1470, G : 6.788562774658203\n",
      "EPOCH : 14, step : 1471, D : 5.815783977508545\n",
      "EPOCH : 14, step : 1472, G : 6.844844341278076\n",
      "EPOCH : 14, step : 1473, D : 5.956786632537842\n",
      "EPOCH : 14, step : 1474, G : 6.966946125030518\n",
      "EPOCH : 14, step : 1475, D : 5.730959892272949\n",
      "EPOCH : 14, step : 1476, G : 7.336817264556885\n",
      "EPOCH : 14, step : 1477, D : 6.024975776672363\n",
      "EPOCH : 14, step : 1478, G : 6.434791088104248\n",
      "EPOCH : 14, step : 1479, D : 6.3615264892578125\n",
      "EPOCH : 14, step : 1480, G : 6.876489639282227\n",
      "EPOCH : 14, step : 1481, D : 5.978713512420654\n",
      "EPOCH : 14, step : 1482, G : 6.998020648956299\n",
      "EPOCH : 14, step : 1483, D : 6.1031174659729\n",
      "EPOCH : 14, step : 1484, G : 7.003813743591309\n",
      "EPOCH : 14, step : 1485, D : 5.884425640106201\n",
      "EPOCH : 14, step : 1486, G : 6.825559139251709\n",
      "EPOCH : 14, step : 1487, D : 5.773701190948486\n",
      "EPOCH : 14, step : 1488, G : 6.836695194244385\n",
      "EPOCH : 14, step : 1489, D : 5.907358646392822\n",
      "EPOCH : 14, step : 1490, G : 7.039529323577881\n",
      "EPOCH : 14, step : 1491, D : 5.94879674911499\n",
      "EPOCH : 14, step : 1492, G : 6.021557807922363\n",
      "EPOCH : 14, step : 1493, D : 6.14711856842041\n",
      "EPOCH : 14, step : 1494, G : 6.932137966156006\n",
      "EPOCH : 14, step : 1495, D : 5.897701740264893\n",
      "EPOCH : 14, step : 1496, G : 6.675639629364014\n",
      "EPOCH : 14, step : 1497, D : 5.9046101570129395\n",
      "EPOCH : 14, step : 1498, G : 6.643944263458252\n",
      "EPOCH : 14, step : 1499, D : 5.771801471710205\n",
      "EPOCH : 14, step : 1500, G : 6.762011528015137\n",
      "EPOCH : 14, step : 1501, D : 5.830923557281494\n",
      "EPOCH : 14, step : 1502, G : 6.797565460205078\n",
      "EPOCH : 14, step : 1503, D : 5.863805770874023\n",
      "EPOCH : 14, step : 1504, G : 6.9636712074279785\n",
      "EPOCH : 14, step : 1505, D : 5.893337726593018\n",
      "EPOCH : 14, step : 1506, G : 6.923336982727051\n",
      "EPOCH : 14, step : 1507, D : 5.764264106750488\n",
      "EPOCH : 14, step : 1508, G : 7.226078033447266\n",
      "EPOCH : 14, step : 1509, D : 5.919251441955566\n",
      "EPOCH : 14, step : 1510, G : 6.449193954467773\n",
      "EPOCH : 14, step : 1511, D : 6.316089630126953\n",
      "EPOCH : 14, step : 1512, G : 6.417608261108398\n",
      "EPOCH : 14, step : 1513, D : 6.176653861999512\n",
      "EPOCH : 14, step : 1514, G : 7.132903575897217\n",
      "EPOCH : 14, step : 1515, D : 5.929457187652588\n",
      "EPOCH : 14, step : 1516, G : 6.631488800048828\n",
      "EPOCH : 14, step : 1517, D : 5.853156089782715\n",
      "EPOCH : 14, step : 1518, G : 6.605457305908203\n",
      "EPOCH : 14, step : 1519, D : 5.754520893096924\n",
      "EPOCH : 14, step : 1520, G : 6.723207473754883\n",
      "EPOCH : 14, step : 1521, D : 5.941712856292725\n",
      "EPOCH : 14, step : 1522, G : 6.834068775177002\n",
      "EPOCH : 14, step : 1523, D : 5.703685760498047\n",
      "EPOCH : 14, step : 1524, G : 6.81061315536499\n",
      "EPOCH : 14, step : 1525, D : 5.750091552734375\n",
      "EPOCH : 14, step : 1526, G : 6.539332389831543\n",
      "EPOCH : 14, step : 1527, D : 6.06964111328125\n",
      "EPOCH : 14, step : 1528, G : 7.305589199066162\n",
      "EPOCH : 14, step : 1529, D : 6.222343921661377\n",
      "EPOCH : 14, step : 1530, G : 6.59364652633667\n",
      "EPOCH : 14, step : 1531, D : 5.8693647384643555\n",
      "EPOCH : 14, step : 1532, G : 6.692951679229736\n",
      "EPOCH : 14, step : 1533, D : 5.91162633895874\n",
      "EPOCH : 14, step : 1534, G : 6.707729339599609\n",
      "EPOCH : 14, step : 1535, D : 5.8429388999938965\n",
      "EPOCH : 14, step : 1536, G : 6.973100662231445\n",
      "EPOCH : 14, step : 1537, D : 5.6981353759765625\n",
      "EPOCH : 14, step : 1538, G : 6.646330833435059\n",
      "EPOCH : 14, step : 1539, D : 5.79268741607666\n",
      "EPOCH : 14, step : 1540, G : 6.828815460205078\n",
      "EPOCH : 15, step : 1541, D : 5.718534469604492\n",
      "EPOCH : 15, step : 1542, G : 6.957278251647949\n",
      "EPOCH : 15, step : 1543, D : 5.557971954345703\n",
      "EPOCH : 15, step : 1544, G : 7.000763893127441\n",
      "EPOCH : 15, step : 1545, D : 5.486319541931152\n",
      "EPOCH : 15, step : 1546, G : 6.5833659172058105\n",
      "EPOCH : 15, step : 1547, D : 5.862728118896484\n",
      "EPOCH : 15, step : 1548, G : 7.190335750579834\n",
      "EPOCH : 15, step : 1549, D : 6.058358669281006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 15, step : 1550, G : 5.931161403656006\n",
      "EPOCH : 15, step : 1551, D : 6.355254173278809\n",
      "EPOCH : 15, step : 1552, G : 6.323249340057373\n",
      "EPOCH : 15, step : 1553, D : 5.907946586608887\n",
      "EPOCH : 15, step : 1554, G : 6.855928421020508\n",
      "EPOCH : 15, step : 1555, D : 5.879683971405029\n",
      "EPOCH : 15, step : 1556, G : 6.626267910003662\n",
      "EPOCH : 15, step : 1557, D : 5.710831165313721\n",
      "EPOCH : 15, step : 1558, G : 6.514534950256348\n",
      "EPOCH : 15, step : 1559, D : 5.831459045410156\n",
      "EPOCH : 15, step : 1560, G : 6.986136436462402\n",
      "EPOCH : 15, step : 1561, D : 5.6182684898376465\n",
      "EPOCH : 15, step : 1562, G : 6.940507411956787\n",
      "EPOCH : 15, step : 1563, D : 5.692627906799316\n",
      "EPOCH : 15, step : 1564, G : 6.598626613616943\n",
      "EPOCH : 15, step : 1565, D : 5.752634048461914\n",
      "EPOCH : 15, step : 1566, G : 7.064855575561523\n",
      "EPOCH : 15, step : 1567, D : 5.615880012512207\n",
      "EPOCH : 15, step : 1568, G : 6.8637590408325195\n",
      "EPOCH : 15, step : 1569, D : 5.761837482452393\n",
      "EPOCH : 15, step : 1570, G : 6.8672051429748535\n",
      "EPOCH : 15, step : 1571, D : 5.5396342277526855\n",
      "EPOCH : 15, step : 1572, G : 6.890684127807617\n",
      "EPOCH : 15, step : 1573, D : 5.776894569396973\n",
      "EPOCH : 15, step : 1574, G : 6.7846479415893555\n",
      "EPOCH : 15, step : 1575, D : 5.798013210296631\n",
      "EPOCH : 15, step : 1576, G : 5.8311614990234375\n",
      "EPOCH : 15, step : 1577, D : 6.320240497589111\n",
      "EPOCH : 15, step : 1578, G : 6.367532253265381\n",
      "EPOCH : 15, step : 1579, D : 5.895977973937988\n",
      "EPOCH : 15, step : 1580, G : 6.892786026000977\n",
      "EPOCH : 15, step : 1581, D : 5.862695217132568\n",
      "EPOCH : 15, step : 1582, G : 6.418166637420654\n",
      "EPOCH : 15, step : 1583, D : 5.773575305938721\n",
      "EPOCH : 15, step : 1584, G : 6.758937835693359\n",
      "EPOCH : 15, step : 1585, D : 5.597826957702637\n",
      "EPOCH : 15, step : 1586, G : 6.7752885818481445\n",
      "EPOCH : 15, step : 1587, D : 5.7341227531433105\n",
      "EPOCH : 15, step : 1588, G : 6.481032371520996\n",
      "EPOCH : 15, step : 1589, D : 5.847315311431885\n",
      "EPOCH : 15, step : 1590, G : 6.9028143882751465\n",
      "EPOCH : 15, step : 1591, D : 5.770013332366943\n",
      "EPOCH : 15, step : 1592, G : 6.6071577072143555\n",
      "EPOCH : 15, step : 1593, D : 5.742048263549805\n",
      "EPOCH : 15, step : 1594, G : 6.652728080749512\n",
      "EPOCH : 15, step : 1595, D : 5.505621433258057\n",
      "EPOCH : 15, step : 1596, G : 6.813084602355957\n",
      "EPOCH : 15, step : 1597, D : 5.623486042022705\n",
      "EPOCH : 15, step : 1598, G : 6.8569841384887695\n",
      "EPOCH : 15, step : 1599, D : 5.6781744956970215\n",
      "EPOCH : 15, step : 1600, G : 7.014602184295654\n",
      "EPOCH : 15, step : 1601, D : 5.656723976135254\n",
      "EPOCH : 15, step : 1602, G : 6.660827159881592\n",
      "EPOCH : 15, step : 1603, D : 5.79807710647583\n",
      "EPOCH : 15, step : 1604, G : 7.3586506843566895\n",
      "EPOCH : 15, step : 1605, D : 6.3297576904296875\n",
      "EPOCH : 15, step : 1606, G : 6.310781955718994\n",
      "EPOCH : 15, step : 1607, D : 6.047125816345215\n",
      "EPOCH : 15, step : 1608, G : 6.565229892730713\n",
      "EPOCH : 15, step : 1609, D : 5.643561363220215\n",
      "EPOCH : 15, step : 1610, G : 6.92713737487793\n",
      "EPOCH : 15, step : 1611, D : 5.652033805847168\n",
      "EPOCH : 15, step : 1612, G : 6.666136741638184\n",
      "EPOCH : 15, step : 1613, D : 5.6844801902771\n",
      "EPOCH : 15, step : 1614, G : 6.6841139793396\n",
      "EPOCH : 15, step : 1615, D : 5.7926530838012695\n",
      "EPOCH : 15, step : 1616, G : 6.931047439575195\n",
      "EPOCH : 15, step : 1617, D : 5.8137383460998535\n",
      "EPOCH : 15, step : 1618, G : 6.31540060043335\n",
      "EPOCH : 15, step : 1619, D : 5.976336479187012\n",
      "EPOCH : 15, step : 1620, G : 7.165121078491211\n",
      "EPOCH : 15, step : 1621, D : 5.9032464027404785\n",
      "EPOCH : 15, step : 1622, G : 6.6389665603637695\n",
      "EPOCH : 15, step : 1623, D : 5.6156415939331055\n",
      "EPOCH : 15, step : 1624, G : 6.815194606781006\n",
      "EPOCH : 15, step : 1625, D : 5.83348274230957\n",
      "EPOCH : 15, step : 1626, G : 6.4475274085998535\n",
      "EPOCH : 15, step : 1627, D : 6.046482563018799\n",
      "EPOCH : 15, step : 1628, G : 7.038023471832275\n",
      "EPOCH : 15, step : 1629, D : 6.059828758239746\n",
      "EPOCH : 15, step : 1630, G : 6.1148552894592285\n",
      "EPOCH : 15, step : 1631, D : 5.939609527587891\n",
      "EPOCH : 15, step : 1632, G : 6.702365875244141\n",
      "EPOCH : 15, step : 1633, D : 5.844367027282715\n",
      "EPOCH : 15, step : 1634, G : 6.7755255699157715\n",
      "EPOCH : 15, step : 1635, D : 5.767602920532227\n",
      "EPOCH : 15, step : 1636, G : 6.6040568351745605\n",
      "EPOCH : 15, step : 1637, D : 5.609536647796631\n",
      "EPOCH : 15, step : 1638, G : 6.539151668548584\n",
      "EPOCH : 15, step : 1639, D : 5.745274066925049\n",
      "EPOCH : 15, step : 1640, G : 6.745858192443848\n",
      "EPOCH : 15, step : 1641, D : 5.872653007507324\n",
      "EPOCH : 15, step : 1642, G : 6.959340572357178\n",
      "EPOCH : 15, step : 1643, D : 5.668621063232422\n",
      "EPOCH : 15, step : 1644, G : 6.518426418304443\n",
      "EPOCH : 15, step : 1645, D : 5.989465236663818\n",
      "EPOCH : 15, step : 1646, G : 7.107571601867676\n",
      "EPOCH : 15, step : 1647, D : 6.523426055908203\n",
      "EPOCH : 15, step : 1648, G : 6.993226051330566\n",
      "EPOCH : 15, step : 1649, D : 5.740415573120117\n",
      "EPOCH : 15, step : 1650, G : 6.630731105804443\n",
      "EPOCH : 16, step : 1651, D : 5.880889415740967\n",
      "EPOCH : 16, step : 1652, G : 7.294028282165527\n",
      "EPOCH : 16, step : 1653, D : 5.693567276000977\n",
      "EPOCH : 16, step : 1654, G : 6.60573148727417\n",
      "EPOCH : 16, step : 1655, D : 5.616921901702881\n",
      "EPOCH : 16, step : 1656, G : 7.351913928985596\n",
      "EPOCH : 16, step : 1657, D : 5.538491249084473\n",
      "EPOCH : 16, step : 1658, G : 6.720808982849121\n",
      "EPOCH : 16, step : 1659, D : 5.413856506347656\n",
      "EPOCH : 16, step : 1660, G : 6.6706695556640625\n",
      "EPOCH : 16, step : 1661, D : 5.592381000518799\n",
      "EPOCH : 16, step : 1662, G : 6.814455509185791\n",
      "EPOCH : 16, step : 1663, D : 5.437465667724609\n",
      "EPOCH : 16, step : 1664, G : 6.995269775390625\n",
      "EPOCH : 16, step : 1665, D : 5.4825053215026855\n",
      "EPOCH : 16, step : 1666, G : 6.7890305519104\n",
      "EPOCH : 16, step : 1667, D : 5.849427700042725\n",
      "EPOCH : 16, step : 1668, G : 6.9915266036987305\n",
      "EPOCH : 16, step : 1669, D : 5.477052688598633\n",
      "EPOCH : 16, step : 1670, G : 6.825649261474609\n",
      "EPOCH : 16, step : 1671, D : 5.710854530334473\n",
      "EPOCH : 16, step : 1672, G : 7.165831089019775\n",
      "EPOCH : 16, step : 1673, D : 5.660696029663086\n",
      "EPOCH : 16, step : 1674, G : 6.664802551269531\n",
      "EPOCH : 16, step : 1675, D : 6.059816837310791\n",
      "EPOCH : 16, step : 1676, G : 7.29562520980835\n",
      "EPOCH : 16, step : 1677, D : 5.6355156898498535\n",
      "EPOCH : 16, step : 1678, G : 6.561107158660889\n",
      "EPOCH : 16, step : 1679, D : 5.761831283569336\n",
      "EPOCH : 16, step : 1680, G : 6.682032108306885\n",
      "EPOCH : 16, step : 1681, D : 5.626357555389404\n",
      "EPOCH : 16, step : 1682, G : 6.75005578994751\n",
      "EPOCH : 16, step : 1683, D : 5.458045482635498\n",
      "EPOCH : 16, step : 1684, G : 6.630956172943115\n",
      "EPOCH : 16, step : 1685, D : 5.425666332244873\n",
      "EPOCH : 16, step : 1686, G : 6.673344135284424\n",
      "EPOCH : 16, step : 1687, D : 5.689582347869873\n",
      "EPOCH : 16, step : 1688, G : 6.395141124725342\n",
      "EPOCH : 16, step : 1689, D : 5.81129264831543\n",
      "EPOCH : 16, step : 1690, G : 7.1269731521606445\n",
      "EPOCH : 16, step : 1691, D : 6.201314926147461\n",
      "EPOCH : 16, step : 1692, G : 6.28035831451416\n",
      "EPOCH : 16, step : 1693, D : 5.983717918395996\n",
      "EPOCH : 16, step : 1694, G : 6.561523914337158\n",
      "EPOCH : 16, step : 1695, D : 5.7999444007873535\n",
      "EPOCH : 16, step : 1696, G : 6.659693241119385\n",
      "EPOCH : 16, step : 1697, D : 5.946855545043945\n",
      "EPOCH : 16, step : 1698, G : 6.706454277038574\n",
      "EPOCH : 16, step : 1699, D : 5.692556858062744\n",
      "EPOCH : 16, step : 1700, G : 6.532207489013672\n",
      "EPOCH : 16, step : 1701, D : 5.829712867736816\n",
      "EPOCH : 16, step : 1702, G : 7.101460933685303\n",
      "EPOCH : 16, step : 1703, D : 5.906827926635742\n",
      "EPOCH : 16, step : 1704, G : 6.273502349853516\n",
      "EPOCH : 16, step : 1705, D : 5.815870761871338\n",
      "EPOCH : 16, step : 1706, G : 6.939330577850342\n",
      "EPOCH : 16, step : 1707, D : 5.894899845123291\n",
      "EPOCH : 16, step : 1708, G : 6.659786701202393\n",
      "EPOCH : 16, step : 1709, D : 5.6232476234436035\n",
      "EPOCH : 16, step : 1710, G : 6.708748817443848\n",
      "EPOCH : 16, step : 1711, D : 5.595828056335449\n",
      "EPOCH : 16, step : 1712, G : 7.035053253173828\n",
      "EPOCH : 16, step : 1713, D : 5.58092737197876\n",
      "EPOCH : 16, step : 1714, G : 6.6460418701171875\n",
      "EPOCH : 16, step : 1715, D : 5.832525253295898\n",
      "EPOCH : 16, step : 1716, G : 7.252104759216309\n",
      "EPOCH : 16, step : 1717, D : 6.028355598449707\n",
      "EPOCH : 16, step : 1718, G : 6.178659915924072\n",
      "EPOCH : 16, step : 1719, D : 5.715428829193115\n",
      "EPOCH : 16, step : 1720, G : 6.782703876495361\n",
      "EPOCH : 16, step : 1721, D : 5.694040775299072\n",
      "EPOCH : 16, step : 1722, G : 6.743453025817871\n",
      "EPOCH : 16, step : 1723, D : 5.658517360687256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 16, step : 1724, G : 6.683197498321533\n",
      "EPOCH : 16, step : 1725, D : 5.623957633972168\n",
      "EPOCH : 16, step : 1726, G : 6.5950751304626465\n",
      "EPOCH : 16, step : 1727, D : 5.707012176513672\n",
      "EPOCH : 16, step : 1728, G : 7.0923566818237305\n",
      "EPOCH : 16, step : 1729, D : 5.916419506072998\n",
      "EPOCH : 16, step : 1730, G : 6.466928482055664\n",
      "EPOCH : 16, step : 1731, D : 5.799925804138184\n",
      "EPOCH : 16, step : 1732, G : 6.790423393249512\n",
      "EPOCH : 16, step : 1733, D : 5.503425598144531\n",
      "EPOCH : 16, step : 1734, G : 6.9385600090026855\n",
      "EPOCH : 16, step : 1735, D : 5.53016471862793\n",
      "EPOCH : 16, step : 1736, G : 6.460559844970703\n",
      "EPOCH : 16, step : 1737, D : 5.843725681304932\n",
      "EPOCH : 16, step : 1738, G : 7.305351257324219\n",
      "EPOCH : 16, step : 1739, D : 5.825404167175293\n",
      "EPOCH : 16, step : 1740, G : 6.639400005340576\n",
      "EPOCH : 16, step : 1741, D : 5.806029319763184\n",
      "EPOCH : 16, step : 1742, G : 7.14340353012085\n",
      "EPOCH : 16, step : 1743, D : 5.580953598022461\n",
      "EPOCH : 16, step : 1744, G : 6.86839485168457\n",
      "EPOCH : 16, step : 1745, D : 5.632932662963867\n",
      "EPOCH : 16, step : 1746, G : 6.884212017059326\n",
      "EPOCH : 16, step : 1747, D : 5.5523762702941895\n",
      "EPOCH : 16, step : 1748, G : 6.980647563934326\n",
      "EPOCH : 16, step : 1749, D : 5.628194332122803\n",
      "EPOCH : 16, step : 1750, G : 6.957132339477539\n",
      "EPOCH : 16, step : 1751, D : 5.614023685455322\n",
      "EPOCH : 16, step : 1752, G : 6.791899681091309\n",
      "EPOCH : 16, step : 1753, D : 5.645864009857178\n",
      "EPOCH : 16, step : 1754, G : 7.037422180175781\n",
      "EPOCH : 16, step : 1755, D : 5.622415065765381\n",
      "EPOCH : 16, step : 1756, G : 6.406570911407471\n",
      "EPOCH : 16, step : 1757, D : 5.548210620880127\n",
      "EPOCH : 16, step : 1758, G : 6.9689860343933105\n",
      "EPOCH : 16, step : 1759, D : 5.531036853790283\n",
      "EPOCH : 16, step : 1760, G : 6.978829860687256\n",
      "EPOCH : 17, step : 1761, D : 5.488606929779053\n",
      "EPOCH : 17, step : 1762, G : 7.048734188079834\n",
      "EPOCH : 17, step : 1763, D : 5.451258182525635\n",
      "EPOCH : 17, step : 1764, G : 7.1801910400390625\n",
      "EPOCH : 17, step : 1765, D : 5.642269611358643\n",
      "EPOCH : 17, step : 1766, G : 7.048397541046143\n",
      "EPOCH : 17, step : 1767, D : 5.705172061920166\n",
      "EPOCH : 17, step : 1768, G : 7.414358139038086\n",
      "EPOCH : 17, step : 1769, D : 5.730047225952148\n",
      "EPOCH : 17, step : 1770, G : 6.709239959716797\n",
      "EPOCH : 17, step : 1771, D : 5.560301780700684\n",
      "EPOCH : 17, step : 1772, G : 6.96718692779541\n",
      "EPOCH : 17, step : 1773, D : 5.366811275482178\n",
      "EPOCH : 17, step : 1774, G : 7.026952266693115\n",
      "EPOCH : 17, step : 1775, D : 5.597405910491943\n",
      "EPOCH : 17, step : 1776, G : 6.139928817749023\n",
      "EPOCH : 17, step : 1777, D : 6.171605587005615\n",
      "EPOCH : 17, step : 1778, G : 7.046390533447266\n",
      "EPOCH : 17, step : 1779, D : 5.89898681640625\n",
      "EPOCH : 17, step : 1780, G : 6.542246341705322\n",
      "EPOCH : 17, step : 1781, D : 5.773859024047852\n",
      "EPOCH : 17, step : 1782, G : 6.797463417053223\n",
      "EPOCH : 17, step : 1783, D : 5.383188724517822\n",
      "EPOCH : 17, step : 1784, G : 6.662809371948242\n",
      "EPOCH : 17, step : 1785, D : 5.452625274658203\n",
      "EPOCH : 17, step : 1786, G : 6.925657272338867\n",
      "EPOCH : 17, step : 1787, D : 5.8599772453308105\n",
      "EPOCH : 17, step : 1788, G : 6.214719772338867\n",
      "EPOCH : 17, step : 1789, D : 5.691510200500488\n",
      "EPOCH : 17, step : 1790, G : 7.222530364990234\n",
      "EPOCH : 17, step : 1791, D : 5.627224922180176\n",
      "EPOCH : 17, step : 1792, G : 6.653184413909912\n",
      "EPOCH : 17, step : 1793, D : 5.521611213684082\n",
      "EPOCH : 17, step : 1794, G : 6.716492652893066\n",
      "EPOCH : 17, step : 1795, D : 5.454633712768555\n",
      "EPOCH : 17, step : 1796, G : 6.92111349105835\n",
      "EPOCH : 17, step : 1797, D : 5.618140697479248\n",
      "EPOCH : 17, step : 1798, G : 6.6215901374816895\n",
      "EPOCH : 17, step : 1799, D : 5.611495494842529\n",
      "EPOCH : 17, step : 1800, G : 6.4788336753845215\n",
      "EPOCH : 17, step : 1801, D : 5.572205543518066\n",
      "EPOCH : 17, step : 1802, G : 7.02202844619751\n",
      "EPOCH : 17, step : 1803, D : 5.550257205963135\n",
      "EPOCH : 17, step : 1804, G : 6.783787250518799\n",
      "EPOCH : 17, step : 1805, D : 5.326205730438232\n",
      "EPOCH : 17, step : 1806, G : 7.0421648025512695\n",
      "EPOCH : 17, step : 1807, D : 5.49650764465332\n",
      "EPOCH : 17, step : 1808, G : 6.49955940246582\n",
      "EPOCH : 17, step : 1809, D : 5.753097057342529\n",
      "EPOCH : 17, step : 1810, G : 7.152697563171387\n",
      "EPOCH : 17, step : 1811, D : 5.962883472442627\n",
      "EPOCH : 17, step : 1812, G : 6.617974281311035\n",
      "EPOCH : 17, step : 1813, D : 5.634513854980469\n",
      "EPOCH : 17, step : 1814, G : 6.653348922729492\n",
      "EPOCH : 17, step : 1815, D : 5.745670795440674\n",
      "EPOCH : 17, step : 1816, G : 6.801002025604248\n",
      "EPOCH : 17, step : 1817, D : 5.442249774932861\n",
      "EPOCH : 17, step : 1818, G : 6.786758899688721\n",
      "EPOCH : 17, step : 1819, D : 5.630006313323975\n",
      "EPOCH : 17, step : 1820, G : 6.842729568481445\n",
      "EPOCH : 17, step : 1821, D : 5.254482269287109\n",
      "EPOCH : 17, step : 1822, G : 6.8298234939575195\n",
      "EPOCH : 17, step : 1823, D : 5.438024997711182\n",
      "EPOCH : 17, step : 1824, G : 6.823685646057129\n",
      "EPOCH : 17, step : 1825, D : 5.394275188446045\n",
      "EPOCH : 17, step : 1826, G : 6.83123779296875\n",
      "EPOCH : 17, step : 1827, D : 5.387537002563477\n",
      "EPOCH : 17, step : 1828, G : 6.986003398895264\n",
      "EPOCH : 17, step : 1829, D : 5.573559761047363\n",
      "EPOCH : 17, step : 1830, G : 6.3061299324035645\n",
      "EPOCH : 17, step : 1831, D : 5.985295295715332\n",
      "EPOCH : 17, step : 1832, G : 7.232700824737549\n",
      "EPOCH : 17, step : 1833, D : 5.967857360839844\n",
      "EPOCH : 17, step : 1834, G : 6.596124649047852\n",
      "EPOCH : 17, step : 1835, D : 5.657463550567627\n",
      "EPOCH : 17, step : 1836, G : 6.536501407623291\n",
      "EPOCH : 17, step : 1837, D : 5.687389373779297\n",
      "EPOCH : 17, step : 1838, G : 6.758876323699951\n",
      "EPOCH : 17, step : 1839, D : 5.458883762359619\n",
      "EPOCH : 17, step : 1840, G : 6.3511152267456055\n",
      "EPOCH : 17, step : 1841, D : 5.693764686584473\n",
      "EPOCH : 17, step : 1842, G : 6.858617305755615\n",
      "EPOCH : 17, step : 1843, D : 5.5031867027282715\n",
      "EPOCH : 17, step : 1844, G : 6.501398086547852\n",
      "EPOCH : 17, step : 1845, D : 5.599205017089844\n",
      "EPOCH : 17, step : 1846, G : 7.0242838859558105\n",
      "EPOCH : 17, step : 1847, D : 5.723635196685791\n",
      "EPOCH : 17, step : 1848, G : 6.455371379852295\n",
      "EPOCH : 17, step : 1849, D : 5.610860824584961\n",
      "EPOCH : 17, step : 1850, G : 6.625217437744141\n",
      "EPOCH : 17, step : 1851, D : 5.413876056671143\n",
      "EPOCH : 17, step : 1852, G : 7.141499996185303\n",
      "EPOCH : 17, step : 1853, D : 5.885251045227051\n",
      "EPOCH : 17, step : 1854, G : 6.570683002471924\n",
      "EPOCH : 17, step : 1855, D : 5.835049629211426\n",
      "EPOCH : 17, step : 1856, G : 6.731369972229004\n",
      "EPOCH : 17, step : 1857, D : 5.333095073699951\n",
      "EPOCH : 17, step : 1858, G : 7.117640972137451\n",
      "EPOCH : 17, step : 1859, D : 5.458803653717041\n",
      "EPOCH : 17, step : 1860, G : 6.13386344909668\n",
      "EPOCH : 17, step : 1861, D : 5.655459880828857\n",
      "EPOCH : 17, step : 1862, G : 7.034818172454834\n",
      "EPOCH : 17, step : 1863, D : 5.622153282165527\n",
      "EPOCH : 17, step : 1864, G : 6.794580936431885\n",
      "EPOCH : 17, step : 1865, D : 5.496777534484863\n",
      "EPOCH : 17, step : 1866, G : 6.678702354431152\n",
      "EPOCH : 17, step : 1867, D : 5.407710075378418\n",
      "EPOCH : 17, step : 1868, G : 7.019374370574951\n",
      "EPOCH : 17, step : 1869, D : 5.444278240203857\n",
      "EPOCH : 17, step : 1870, G : 6.344965934753418\n",
      "EPOCH : 18, step : 1871, D : 5.908384323120117\n",
      "EPOCH : 18, step : 1872, G : 7.723485469818115\n",
      "EPOCH : 18, step : 1873, D : 5.794916152954102\n",
      "EPOCH : 18, step : 1874, G : 6.189782619476318\n",
      "EPOCH : 18, step : 1875, D : 5.556186676025391\n",
      "EPOCH : 18, step : 1876, G : 6.82638692855835\n",
      "EPOCH : 18, step : 1877, D : 5.412510395050049\n",
      "EPOCH : 18, step : 1878, G : 6.828631401062012\n",
      "EPOCH : 18, step : 1879, D : 5.352479457855225\n",
      "EPOCH : 18, step : 1880, G : 6.741428852081299\n",
      "EPOCH : 18, step : 1881, D : 5.562836170196533\n",
      "EPOCH : 18, step : 1882, G : 6.703252792358398\n",
      "EPOCH : 18, step : 1883, D : 5.436999797821045\n",
      "EPOCH : 18, step : 1884, G : 6.904384613037109\n",
      "EPOCH : 18, step : 1885, D : 5.357570171356201\n",
      "EPOCH : 18, step : 1886, G : 6.773697853088379\n",
      "EPOCH : 18, step : 1887, D : 5.50164794921875\n",
      "EPOCH : 18, step : 1888, G : 7.301811218261719\n",
      "EPOCH : 18, step : 1889, D : 5.633406162261963\n",
      "EPOCH : 18, step : 1890, G : 6.055665016174316\n",
      "EPOCH : 18, step : 1891, D : 6.075461387634277\n",
      "EPOCH : 18, step : 1892, G : 6.773603916168213\n",
      "EPOCH : 18, step : 1893, D : 5.518487930297852\n",
      "EPOCH : 18, step : 1894, G : 7.076883316040039\n",
      "EPOCH : 18, step : 1895, D : 5.402717590332031\n",
      "EPOCH : 18, step : 1896, G : 6.640092849731445\n",
      "EPOCH : 18, step : 1897, D : 5.6186933517456055\n",
      "EPOCH : 18, step : 1898, G : 6.82956075668335\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 18, step : 1899, D : 5.493350982666016\n",
      "EPOCH : 18, step : 1900, G : 6.513060092926025\n",
      "EPOCH : 18, step : 1901, D : 5.811444282531738\n",
      "EPOCH : 18, step : 1902, G : 6.968311786651611\n",
      "EPOCH : 18, step : 1903, D : 5.721766948699951\n",
      "EPOCH : 18, step : 1904, G : 6.639192581176758\n",
      "EPOCH : 18, step : 1905, D : 5.5512495040893555\n",
      "EPOCH : 18, step : 1906, G : 6.510802268981934\n",
      "EPOCH : 18, step : 1907, D : 5.560451984405518\n",
      "EPOCH : 18, step : 1908, G : 6.562515735626221\n",
      "EPOCH : 18, step : 1909, D : 5.573428630828857\n",
      "EPOCH : 18, step : 1910, G : 6.315622806549072\n",
      "EPOCH : 18, step : 1911, D : 5.861034393310547\n",
      "EPOCH : 18, step : 1912, G : 7.420148849487305\n",
      "EPOCH : 18, step : 1913, D : 6.302074909210205\n",
      "EPOCH : 18, step : 1914, G : 7.230831146240234\n",
      "EPOCH : 18, step : 1915, D : 5.684798240661621\n",
      "EPOCH : 18, step : 1916, G : 5.868161678314209\n",
      "EPOCH : 18, step : 1917, D : 5.971778869628906\n",
      "EPOCH : 18, step : 1918, G : 6.66243314743042\n",
      "EPOCH : 18, step : 1919, D : 5.381469249725342\n",
      "EPOCH : 18, step : 1920, G : 6.691605091094971\n",
      "EPOCH : 18, step : 1921, D : 5.319774627685547\n",
      "EPOCH : 18, step : 1922, G : 6.578063011169434\n",
      "EPOCH : 18, step : 1923, D : 5.700997352600098\n",
      "EPOCH : 18, step : 1924, G : 6.772886753082275\n",
      "EPOCH : 18, step : 1925, D : 5.2481608390808105\n",
      "EPOCH : 18, step : 1926, G : 6.591717720031738\n",
      "EPOCH : 18, step : 1927, D : 5.2415337562561035\n",
      "EPOCH : 18, step : 1928, G : 6.704776763916016\n",
      "EPOCH : 18, step : 1929, D : 5.2656731605529785\n",
      "EPOCH : 18, step : 1930, G : 6.8187336921691895\n",
      "EPOCH : 18, step : 1931, D : 5.212408065795898\n",
      "EPOCH : 18, step : 1932, G : 6.582149982452393\n",
      "EPOCH : 18, step : 1933, D : 5.351676940917969\n",
      "EPOCH : 18, step : 1934, G : 6.866729736328125\n",
      "EPOCH : 18, step : 1935, D : 5.249651908874512\n",
      "EPOCH : 18, step : 1936, G : 6.749555587768555\n",
      "EPOCH : 18, step : 1937, D : 5.830923080444336\n",
      "EPOCH : 18, step : 1938, G : 6.676017761230469\n",
      "EPOCH : 18, step : 1939, D : 5.447546005249023\n",
      "EPOCH : 18, step : 1940, G : 6.9953107833862305\n",
      "EPOCH : 18, step : 1941, D : 5.640552520751953\n",
      "EPOCH : 18, step : 1942, G : 6.562956809997559\n",
      "EPOCH : 18, step : 1943, D : 5.5923333168029785\n",
      "EPOCH : 18, step : 1944, G : 6.7249884605407715\n",
      "EPOCH : 18, step : 1945, D : 5.274438381195068\n",
      "EPOCH : 18, step : 1946, G : 6.557241916656494\n",
      "EPOCH : 18, step : 1947, D : 5.1389265060424805\n",
      "EPOCH : 18, step : 1948, G : 6.754011154174805\n",
      "EPOCH : 18, step : 1949, D : 5.365070343017578\n",
      "EPOCH : 18, step : 1950, G : 6.685695171356201\n",
      "EPOCH : 18, step : 1951, D : 5.467014789581299\n",
      "EPOCH : 18, step : 1952, G : 6.29746150970459\n",
      "EPOCH : 18, step : 1953, D : 5.739627361297607\n",
      "EPOCH : 18, step : 1954, G : 7.2302141189575195\n",
      "EPOCH : 18, step : 1955, D : 5.995707988739014\n",
      "EPOCH : 18, step : 1956, G : 6.684556007385254\n",
      "EPOCH : 18, step : 1957, D : 5.487505912780762\n",
      "EPOCH : 18, step : 1958, G : 6.392894268035889\n",
      "EPOCH : 18, step : 1959, D : 5.312615871429443\n",
      "EPOCH : 18, step : 1960, G : 6.997740745544434\n",
      "EPOCH : 18, step : 1961, D : 5.487710475921631\n",
      "EPOCH : 18, step : 1962, G : 6.094667434692383\n",
      "EPOCH : 18, step : 1963, D : 5.681687831878662\n",
      "EPOCH : 18, step : 1964, G : 6.9984564781188965\n",
      "EPOCH : 18, step : 1965, D : 5.719257354736328\n",
      "EPOCH : 18, step : 1966, G : 6.355355739593506\n",
      "EPOCH : 18, step : 1967, D : 5.430710315704346\n",
      "EPOCH : 18, step : 1968, G : 7.01057767868042\n",
      "EPOCH : 18, step : 1969, D : 5.326223373413086\n",
      "EPOCH : 18, step : 1970, G : 6.722660541534424\n",
      "EPOCH : 19, step : 1981, D : 5.430050373077393\n",
      "EPOCH : 19, step : 1982, G : 7.090384483337402\n",
      "EPOCH : 19, step : 1983, D : 5.336948871612549\n",
      "EPOCH : 19, step : 1984, G : 6.8251471519470215\n",
      "EPOCH : 19, step : 1985, D : 5.040884017944336\n",
      "EPOCH : 19, step : 1986, G : 7.0895490646362305\n",
      "EPOCH : 19, step : 1987, D : 5.141147613525391\n",
      "EPOCH : 19, step : 1988, G : 6.77548885345459\n",
      "EPOCH : 19, step : 1989, D : 5.360130310058594\n",
      "EPOCH : 19, step : 1990, G : 7.144700050354004\n",
      "EPOCH : 19, step : 1991, D : 5.325099945068359\n",
      "EPOCH : 19, step : 1992, G : 7.161004543304443\n",
      "EPOCH : 19, step : 1993, D : 5.341325283050537\n",
      "EPOCH : 19, step : 1994, G : 6.995373725891113\n",
      "EPOCH : 19, step : 1995, D : 5.33340311050415\n",
      "EPOCH : 19, step : 1996, G : 6.635715961456299\n",
      "EPOCH : 19, step : 1997, D : 5.572259902954102\n",
      "EPOCH : 19, step : 1998, G : 7.213375091552734\n",
      "EPOCH : 19, step : 1999, D : 5.8524675369262695\n",
      "EPOCH : 19, step : 2000, G : 6.444090366363525\n",
      "EPOCH : 19, step : 2001, D : 5.182430267333984\n",
      "EPOCH : 19, step : 2002, G : 6.369417190551758\n",
      "EPOCH : 19, step : 2003, D : 5.44632625579834\n",
      "EPOCH : 19, step : 2004, G : 6.728837490081787\n",
      "EPOCH : 19, step : 2005, D : 5.370070457458496\n",
      "EPOCH : 19, step : 2006, G : 6.63298225402832\n",
      "EPOCH : 19, step : 2007, D : 5.467018127441406\n",
      "EPOCH : 19, step : 2008, G : 6.442509174346924\n",
      "EPOCH : 19, step : 2009, D : 5.345675468444824\n",
      "EPOCH : 19, step : 2010, G : 6.880503177642822\n",
      "EPOCH : 19, step : 2011, D : 5.4113874435424805\n",
      "EPOCH : 19, step : 2012, G : 6.842450141906738\n",
      "EPOCH : 19, step : 2013, D : 5.387347221374512\n",
      "EPOCH : 19, step : 2014, G : 6.630805492401123\n",
      "EPOCH : 19, step : 2015, D : 5.429126262664795\n",
      "EPOCH : 19, step : 2016, G : 6.763107776641846\n",
      "EPOCH : 19, step : 2017, D : 5.340802192687988\n",
      "EPOCH : 19, step : 2018, G : 6.5580644607543945\n",
      "EPOCH : 19, step : 2019, D : 5.2860589027404785\n",
      "EPOCH : 19, step : 2020, G : 6.643695831298828\n",
      "EPOCH : 19, step : 2021, D : 5.192184925079346\n",
      "EPOCH : 19, step : 2022, G : 7.065283298492432\n",
      "EPOCH : 19, step : 2023, D : 5.008975028991699\n",
      "EPOCH : 19, step : 2024, G : 6.845376968383789\n",
      "EPOCH : 19, step : 2025, D : 5.342042922973633\n",
      "EPOCH : 19, step : 2026, G : 6.458641529083252\n",
      "EPOCH : 19, step : 2027, D : 5.321635723114014\n",
      "EPOCH : 19, step : 2028, G : 7.00357723236084\n",
      "EPOCH : 19, step : 2029, D : 5.448195457458496\n",
      "EPOCH : 19, step : 2030, G : 6.011289119720459\n",
      "EPOCH : 19, step : 2031, D : 5.92469596862793\n",
      "EPOCH : 19, step : 2032, G : 6.738491058349609\n",
      "EPOCH : 19, step : 2033, D : 5.311046600341797\n",
      "EPOCH : 19, step : 2034, G : 7.175422668457031\n",
      "EPOCH : 19, step : 2035, D : 5.373813152313232\n",
      "EPOCH : 19, step : 2036, G : 6.599700450897217\n",
      "EPOCH : 19, step : 2037, D : 5.434074401855469\n",
      "EPOCH : 19, step : 2038, G : 6.651375770568848\n",
      "EPOCH : 19, step : 2039, D : 5.307665824890137\n",
      "EPOCH : 19, step : 2040, G : 6.546021938323975\n",
      "EPOCH : 19, step : 2041, D : 5.595674991607666\n",
      "EPOCH : 19, step : 2042, G : 6.702718257904053\n",
      "EPOCH : 19, step : 2043, D : 5.272607803344727\n",
      "EPOCH : 19, step : 2044, G : 6.900831699371338\n",
      "EPOCH : 19, step : 2045, D : 5.417788982391357\n",
      "EPOCH : 19, step : 2046, G : 7.093989849090576\n",
      "EPOCH : 19, step : 2047, D : 5.236942768096924\n",
      "EPOCH : 19, step : 2048, G : 6.556779384613037\n",
      "EPOCH : 19, step : 2049, D : 5.548031330108643\n",
      "EPOCH : 19, step : 2050, G : 6.972465515136719\n",
      "EPOCH : 19, step : 2051, D : 5.544366836547852\n",
      "EPOCH : 19, step : 2052, G : 6.501166820526123\n",
      "EPOCH : 19, step : 2053, D : 5.386960506439209\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# encoding: utf-8\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "import datetime\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "from model import single_DR_GAN_model as single_model\n",
    "from model import multiple_DR_GAN_model as multi_model\n",
    "from util.create_randomdata import create_randomdata\n",
    "from train_single_DRGAN import train_single_DRGAN\n",
    "from train_multiple_DRGAN import train_multiple_DRGAN\n",
    "from Generate_Image import Generate_Image\n",
    "import pdb\n",
    "\n",
    "import easydict\n",
    "args = easydict.EasyDict({\n",
    "    \"lr\": 0.0002,\n",
    "    \"beta1\": 0.5,\n",
    "    \"beta2\": 0.999,\n",
    "    \"epochs\": 1000,\n",
    "    \"batch_size\": 64,\n",
    "    \"save_dir\": 'snapshot',\n",
    "    \"save_freq\": 1,\n",
    "    \"cuda\": False,\n",
    "})\n",
    "\n",
    "# update args and print\n",
    "args.save_dir = os.path.join(args.save_dir, 'Single',datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S'))\n",
    "\n",
    "os.makedirs(args.save_dir)\n",
    "\n",
    "print(\"Parameters:\")\n",
    "for attr, value in sorted(args.__dict__.items()):\n",
    "    text =\"\\t{}={}\\n\".format(attr.upper(), value)\n",
    "    print(text)\n",
    "    with open('{}/Parameters.txt'.format(args.save_dir),'a') as f:\n",
    "        f.write(text)\n",
    "\n",
    "# Define model\n",
    "D = single_model.Discriminator(Nd, Np, channel_num)\n",
    "G = single_model.Generator(Np, Nz, channel_num)\n",
    "\n",
    "# Train model\n",
    "train_single_DRGAN(images, id_labels, pose_labels, Nd, Np, Nz, D, G, args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6987, 3, 110, 110)\n",
      "(6987,)\n"
     ]
    }
   ],
   "source": [
    "print(images.shape)\n",
    "print(id_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 5. 学習結果の読み込み， 画像の生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pdb\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "#  DR-GAN の Generator を用いる画像生成関数\n",
    "def Generate_Image(images, pose_number, Np,Nz, G_model, args):\n",
    "    \"\"\"\n",
    "    Generate_Image with learned Generator\n",
    "\n",
    "    ### input\n",
    "    images      : source images\n",
    "    pose_number : integer which specify pose to generate image from source image\n",
    "    Nz          : size of noise vecotr\n",
    "    G_model     : learned Generator\n",
    "    args        : options\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    if args.cuda:\n",
    "        G_model.cuda()\n",
    "        \n",
    "    G_model.eval()\n",
    "\n",
    "    features = []\n",
    "    \n",
    "    batch_size = images.shape[0]\n",
    "    pose_code = np.zeros([batch_size, Np])\n",
    "    pose_code[:, pose_number] = 1\n",
    "    batch_image = torch.FloatTensor(images)\n",
    "    batch_pose_code = torch.FloatTensor(pose_code) # Condition 付に使用\n",
    "    fixed_noise = torch.FloatTensor(np.random.uniform(-1,1, (batch_size, Nz)))\n",
    "\n",
    "    batch_image, fixed_noise, batch_pose_code = \\\n",
    "        batch_image.cuda(), fixed_noise.cuda(), batch_pose_code.cuda()\n",
    "\n",
    "    batch_image, fixed_noise, batch_pose_code = \\\n",
    "         Variable(batch_image), Variable(fixed_noise), Variable(batch_pose_code)\n",
    "\n",
    "    # Generatorでイメージ生成\n",
    "    generated = G_model(batch_image, batch_pose_code, fixed_noise)\n",
    "    features.append(G_model.features)\n",
    "\n",
    "    features = torch.cat(features)\n",
    "    \n",
    "    return convert_image(generated.data.cpu().numpy())\n",
    "\n",
    "def convert_image(data):\n",
    "\n",
    "    img = data.transpose(0, 2, 3, 1)+1\n",
    "    img = img / 2.0\n",
    "    img = img * 255.\n",
    "    img = img[:,:,:,[2,1,0]]\n",
    "    \n",
    "    return img.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anpei/.local/lib/python3.7/site-packages/torch/serialization.py:493: SourceChangeWarning: source code of class 'torch.nn.modules.container.Sequential' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/anpei/.local/lib/python3.7/site-packages/torch/serialization.py:493: SourceChangeWarning: source code of class 'torch.nn.modules.conv.Conv2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/anpei/.local/lib/python3.7/site-packages/torch/serialization.py:493: SourceChangeWarning: source code of class 'torch.nn.modules.batchnorm.BatchNorm2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/anpei/.local/lib/python3.7/site-packages/torch/serialization.py:493: SourceChangeWarning: source code of class 'torch.nn.modules.activation.ELU' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/anpei/.local/lib/python3.7/site-packages/torch/serialization.py:493: SourceChangeWarning: source code of class 'torch.nn.modules.padding.ZeroPad2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/anpei/.local/lib/python3.7/site-packages/torch/serialization.py:493: SourceChangeWarning: source code of class 'torch.nn.modules.pooling.AvgPool2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/anpei/.local/lib/python3.7/site-packages/torch/serialization.py:493: SourceChangeWarning: source code of class 'torch.nn.modules.conv.ConvTranspose2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/anpei/.local/lib/python3.7/site-packages/torch/serialization.py:493: SourceChangeWarning: source code of class 'torch.nn.modules.activation.Tanh' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/anpei/.local/lib/python3.7/site-packages/torch/serialization.py:493: SourceChangeWarning: source code of class 'torch.nn.modules.linear.Linear' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    }
   ],
   "source": [
    "G = torch.load('./epoch780_G.pt')\n",
    "jpg_image = convert_image(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recursion_change_bn(module):\n",
    "    if isinstance(module, torch.nn.BatchNorm2d):\n",
    "        module.track_running_stats = 1\n",
    "    else:\n",
    "        for i, (name, module1) in enumerate(module._modules.items()):\n",
    "            module1 = recursion_change_bn(module1)\n",
    "    return module\n",
    "\n",
    "# check_point = torch.load(check_point_file_path)\n",
    "model = G\n",
    "for i, (name, module) in enumerate(model._modules.items()):\n",
    "    module = recursion_change_bn(model)\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.dump_patches = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ZeroPad2d' object has no attribute 'value'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-a66312dc7001>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m })\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mgenerated_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGenerate_Image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimage_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrcParams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'figure.figsize'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m15.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m15.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-6e38a896d5c0>\u001b[0m in \u001b[0;36mGenerate_Image\u001b[0;34m(images, pose_number, Np, Nz, G_model, args)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;31m# Generatorでイメージ生成\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0mgenerated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mG_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_pose_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfixed_noise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m     \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/MultiSynthesis/DR-GAN/model/single_DR_GAN_model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, pose, noise)\u001b[0m\n\u001b[1;32m    253\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mG_enc_convLayers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Bxchx96x96 -> Bx320x1x1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m320\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/padding.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'constant'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    583\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m--> 585\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m    586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ZeroPad2d' object has no attribute 'value'"
     ]
    }
   ],
   "source": [
    "# 同一ポーズで複数の顔写真を生成テスト\n",
    "\n",
    "import easydict\n",
    "\n",
    "Np = 2\n",
    "n = 4\n",
    "pose = 0\n",
    "image_list = np.random.randint(0,6900, (1,n))[0]\n",
    "args = easydict.EasyDict({\n",
    "    \"cuda\": False,\n",
    "})\n",
    "generated_image = Generate_Image(images[image_list], pose, Np, 50, G, args)\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (15.0, 15.0)\n",
    "for i in range(n):\n",
    "    plt.subplot(2, n, i+1)\n",
    "    plt.title('No.:{}, id:{}, pose:{}'.format(image_list[i], id_labels[image_list[i]], pose_labels[image_list[i]]))\n",
    "    plt.imshow(jpg_image[image_list[i]])\n",
    "    plt.subplot(2, n, n+i+1)\n",
    "    plt.imshow(generated_image[i])\n",
    "\n",
    "axes = plt.gcf().get_axes()\n",
    "for ax in axes:\n",
    "    ax.tick_params(labelbottom=\"off\",bottom=\"off\") # x軸の削除\n",
    "    ax.tick_params(labelleft=\"off\",left=\"off\") # y軸の削除\n",
    "    ax.set_xticklabels([]) \n",
    "    \n",
    "plt.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=0, hspace=0)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ZeroPad2d' object has no attribute 'value'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-579089ced894>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mpose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mgenerated_image_pose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGenerate_Image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimage_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNp\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mG\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mgenerated_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerated_image_pose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-6e38a896d5c0>\u001b[0m in \u001b[0;36mGenerate_Image\u001b[0;34m(images, pose_number, Np, Nz, G_model, args)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;31m# Generatorでイメージ生成\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0mgenerated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mG_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_pose_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfixed_noise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m     \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/MultiSynthesis/DR-GAN/model/single_DR_GAN_model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, pose, noise)\u001b[0m\n\u001b[1;32m    253\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mG_enc_convLayers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Bxchx96x96 -> Bx320x1x1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m320\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/padding.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'constant'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    583\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m--> 585\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m    586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ZeroPad2d' object has no attribute 'value'"
     ]
    }
   ],
   "source": [
    "# 同一写真で複数のポーズを生成テスト\n",
    "\n",
    "Np = 2\n",
    "n = 1\n",
    "image_list = np.random.randint(0,6900, (1,n))[0]\n",
    "\n",
    "\n",
    "generated_image = []\n",
    "\n",
    "for i in range(Np):\n",
    "        pose = i\n",
    "        generated_image_pose = Generate_Image(images[image_list], pose, Np,  50, G , args)\n",
    "        generated_image.append(generated_image_pose)\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (15.0, 15.0)\n",
    "for i in range(Np):\n",
    "    plt.subplot(2, Np, i+1)\n",
    "    plt.title('No.:{}, pose:{}'.format(image_list[0], pose_labels[image_list[0]]))\n",
    "    plt.imshow(jpg_image[image_list[0]])\n",
    "    \n",
    "    plt.subplot(2, Np, i+1+Np)\n",
    "    plt.title('pose:{}'.format(i))\n",
    "    plt.imshow(generated_image[i].squeeze())\n",
    "\n",
    "axes = plt.gcf().get_axes()\n",
    "for ax in axes:\n",
    "    ax.tick_params(labelbottom=\"off\",bottom=\"off\") # x軸の削除\n",
    "    ax.tick_params(labelleft=\"off\",left=\"off\") # y軸の削除\n",
    "    ax.set_xticklabels([]) \n",
    "\n",
    "plt.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=0, hspace=0)\n",
    "fig = plt.gcf()\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
